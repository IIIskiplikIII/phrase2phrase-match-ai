{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "---Tensorflow is running with GPU Power now---\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\sample_submission.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\test.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#import mlflow\n",
    "#from mlflow import log_metric, log_param, log_artifacts\n",
    "#import mlflow.tensorflow\n",
    "#from mlflow import pyfunc\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(f'---Tensorflow is running with GPU Power now---')\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "\n",
    "\n",
    "random_state=42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n",
    "#kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "\n",
    "# change your local path here\n",
    "if iskaggle:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'input')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\n",
    "else:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(PHRASES_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\python-workspace\\\\phrase2phrase-match-ai\\\\data'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of loaded trainset: 36473\n",
      "Length of loaded testset: 36\n",
      "Length of loaded cpc_codeset: 260476\n"
     ]
    }
   ],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "CSV_FILE_CPC='titles.csv'\n",
    "CPC_PATH='input\\\\cpc-codes'\n",
    "\n",
    "def load_csv_data(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_csv_data_manuel(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "\n",
    "train = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\n",
    "test = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\n",
    "cpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)\n",
    "\n",
    "\n",
    "print(f'Length of loaded trainset: {len(train)}')\n",
    "print(f'Length of loaded testset: {len(test)}')\n",
    "print(f'Length of loaded cpc_codeset: {len(cpc_code)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(cpc_code.set_index('code'), on = 'context')\n",
    "test = test.join(cpc_code.set_index('code'), on = 'context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Attributes\n",
    "- id - a unique identifier for a pair of phrases\n",
    "- anchor - the first phrase\n",
    "- target - the second phrase\n",
    "- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
    "- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n",
    "\n",
    "\n",
    "## Score\n",
    "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
    "\n",
    "- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
    "- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
    "- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
    "- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
    "- 0.0 - Unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component composite coating              152\n",
       "sheet supply roller                      150\n",
       "source voltage                           140\n",
       "perfluoroalkyl group                     136\n",
       "el display                               135\n",
       "                                        ... \n",
       "plug nozzle                                2\n",
       "shannon                                    2\n",
       "dry coating composition1                   2\n",
       "peripheral nervous system stimulation      1\n",
       "conduct conducting material                1\n",
       "Name: anchor, Length: 733, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['anchor'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anchor value has 733 different values. Lets look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition                    24\n",
       "data                           22\n",
       "metal                          22\n",
       "motor                          22\n",
       "assembly                       21\n",
       "                               ..\n",
       "switching switch over valve     1\n",
       "switching switch off valve      1\n",
       "switching over valve            1\n",
       "switching off valve             1\n",
       "wooden substrate                1\n",
       "Name: target, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target looks a little bit different. Here we have 29,340 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    12300\n",
       "0.25    11519\n",
       "0.00     7471\n",
       "0.75     4029\n",
       "1.00     1154\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False).sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abatement</th>\n",
       "      <th>A47</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A61</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">wiring trough</th>\n",
       "      <th>F16</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H02</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wood article</th>\n",
       "      <th>B05</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B44</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  target  score  title  section  class  subclass  \\\n",
       "anchor        context                                                       \n",
       "abatement     A47      21      21     21     21       21     21         0   \n",
       "              A61       3       3      3      3        3      3         0   \n",
       "              A62       1       1      1      1        1      1         0   \n",
       "              C01       1       1      1      1        1      1         0   \n",
       "              F16       1       1      1      1        1      1         0   \n",
       "...                    ..     ...    ...    ...      ...    ...       ...   \n",
       "wiring trough F16      27      27     27     27       27     27         0   \n",
       "              H02      18      18     18     18       18     18         0   \n",
       "wood article  B05      28      28     28     28       28     28         0   \n",
       "              B27       1       1      1      1        1      1         0   \n",
       "              B44      27      27     27     27       27     27         0   \n",
       "\n",
       "                       group  main_group  \n",
       "anchor        context                     \n",
       "abatement     A47          0           0  \n",
       "              A61          0           0  \n",
       "              A62          0           0  \n",
       "              C01          0           0  \n",
       "              F16          0           0  \n",
       "...                      ...         ...  \n",
       "wiring trough F16          0           0  \n",
       "              H02          0           0  \n",
       "wood article  B05          0           0  \n",
       "              B27          0           0  \n",
       "              B44          0           0  \n",
       "\n",
       "[1699 rows x 9 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['anchor', 'context']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing cpc text \n",
    "# Build a function around it ?????? !!!!!!!!!!!!!!!!!\n",
    "train['title'] = train.title.apply(lambda text: text.split(';'))\n",
    "train['title'] = train.title.apply(lambda context: ' '.join(context))\n",
    "\n",
    "#train.title.apply(lambda text: (lambda text: text.split(';'))(' '.join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corpus'] = train['anchor'] + ' ' + train['target']\n",
    "train['corpus_w_context'] = train['corpus'] + ' ' +  train['context']\n",
    "train['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']\n",
    "\n",
    "test['corpus'] = test['anchor'] + ' ' + test['target']\n",
    "#test['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifing the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['id','score']].copy()\n",
    "X = train[['id','anchor','target','context', 'corpus', 'title', 'corpus_w_context', 'corpus_w_full_context']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training_target - list: 25531\n",
      "Length of training_content - list: 25531\n",
      "Length of training_content_w_context - list: 25531\n",
      "Length of training_content_full - list: 25531\n",
      "Length of validating_content - list: 10942\n",
      "Length of validating_content_w_context - list: 10942\n",
      "Length of validating_content_full - list: 10942\n",
      "Length of test_content - list: 36\n"
     ]
    }
   ],
   "source": [
    "training_target = X_train['target']\n",
    "print(f'Length of training_target - list: {len(training_target)}')\n",
    "\n",
    "training_content = X_train['corpus']\n",
    "print(f'Length of training_content - list: {len(training_content)}')\n",
    "\n",
    "training_content_w_context = X_train['corpus_w_context']\n",
    "print(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n",
    "\n",
    "training_content_full = X_train['corpus_w_full_context']\n",
    "print(f'Length of training_content_full - list: {len(training_content_full)}')\n",
    "\n",
    "\n",
    "validating_content = X_val['corpus']\n",
    "print(f'Length of validating_content - list: {len(validating_content)}')\n",
    "\n",
    "validating_content_w_context = X_val['corpus_w_context']\n",
    "print(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n",
    "\n",
    "validating_content_full = X_val['corpus_w_full_context']\n",
    "print(f'Length of validating_content_full - list: {len(validating_content_full)}')\n",
    "\n",
    "\n",
    "test_content = test['corpus']\n",
    "print(f'Length of test_content - list: {len(test_content)}')\n",
    "\n",
    "\n",
    "training_labels = y_train['score']\n",
    "validating_labels = y_val['score']\n",
    "\n",
    "training_labels = np.array(training_labels)\n",
    "validating_labels = np.array(validating_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train['score'])\n",
    "\n",
    "training_labels = encoder.transform(training_labels)\n",
    "validating_labels_enc = encoder.transform(validating_labels)\n",
    "\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "validating_labels_enc = validating_labels_enc.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Encoding and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # downloading nltk punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document, alpha=True):\n",
    "    '''Extracing words from a sentence or full text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: str\n",
    "        Text that needs to be tokenized by nltk word_tokenize.\n",
    "    alpha: bool\n",
    "        Keep only letters or not. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of words from the given text.\n",
    "    '''\n",
    "    if alpha == True:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "            if any(c.isalpha() for c in word)\n",
    "        )\n",
    "    else:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    content = []\n",
    "    for doc in docs:\n",
    "        content.append(extract_words(doc))\n",
    "    return content\n",
    "\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(sequences, maxlen=length)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(training_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_line_length = max_length(training_content)\n",
    "word_count = tokenizer.word_counts\n",
    "word_index = tokenizer.word_index\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set (encoded): (25531, 14)\n",
      "Shape validating set (encoded): (10942, 14)\n",
      "Vocabulary size: 7640\n",
      "Max line lenght: 14\n"
     ]
    }
   ],
   "source": [
    "training_content_enc = encode_text(tokenizer, training_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {training_content_enc.shape}')\n",
    "\n",
    "validating_content_enc = encode_text(tokenizer, validating_content, max_line_length)\n",
    "print(f'Shape validating set (encoded): {validating_content_enc.shape}')\n",
    "\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'Max line lenght: {max_line_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.getcwd(), \"data\\\\glove.6B\\\\glove.6B.300d.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file ,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n",
    "\n",
    "According to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7143 words (496 misses)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300 # according to the pretrained network\n",
    "hits = 0\n",
    "misses = 0\n",
    "lr = 5e-6\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new Embedding Layer\n",
    "Now loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    keras.layers.Embedding(    \n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        input_shape = [None],\n",
    "        input_length=max_line_length,\n",
    "        mask_zero=True,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False),\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    #keras.layers.LayerNormalization(),\n",
    "    #Bidirectional(keras.layers.LSTM(300, return_sequences=True)),\n",
    "    #keras.layers.LSTM(300),\n",
    "    #keras.layers.MultiHeadAttention(key_dim=254, num_heads=4, value_dim=20, dropout=0.25),\n",
    "    keras.layers.LSTM(300, return_sequences=True),\n",
    "    keras.layers.LSTM(300),\n",
    "    #keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax' )\n",
    "    ]\n",
    ")\n",
    "\n",
    "#######input = keras.Input(shape=(None, ))\n",
    "#######x = keras.layers.Embedding(\n",
    "#######    vocab_size,\n",
    "#######    embedding_dim,\n",
    "#######    input_shape = [None],\n",
    "#######    input_length=max_line_length,\n",
    "#######    mask_zero=True,\n",
    "#######    weights=[embedding_matrix],\n",
    "#######    trainable = False\n",
    "#######)(input)\n",
    "########x = keras.layers.LayerNormalization()(input)\n",
    "#######x = Bidirectional(keras.layers.LSTM(300, return_sequences=True))(x),\n",
    "#######x = Bidirectional(keras.layers.LSTM(300))(input),\n",
    "#######x = keras.layers.MultiHeadAttention(key_dim=254, num_heads=4, value_dim=20, dropout=0.25)(x, x),\n",
    "########x = keras.layers.LSTM(300, return_sequences=True)(x),\n",
    "########x = keras.layers.LSTM(300)(x),\n",
    "########x = #keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),\n",
    "#######x = keras.layers.BatchNormalization()(x),\n",
    "#######x = keras.layers.Dropout(0.5)(x), \n",
    "#######x = keras.layers.Dense(128)(x),\n",
    "#######x = keras.layers.BatchNormalization()(x),\n",
    "#######x = keras.layers.Activation('relu')(x),\n",
    "#######x = keras.layers.Dropout(0.5)(x),\n",
    "#######output = keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "#model = keras.Model(inputs=input, outputs=output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 300)         2292000   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, None, 300)         721200    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               38528     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,775,285\n",
      "Trainable params: 1,482,429\n",
      "Non-trainable params: 2,292,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logging structure function\n",
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "def get_run_logdir(root_logdir, project):\n",
    "    '''\n",
    "    Returns logdir to the Tensorboard log for a specific project.\n",
    "\n",
    "            Parameters:\n",
    "                    root_logdir (str) : basic logdir from Tensorboard\n",
    "                    project (str): projectname that will be logged in TB\n",
    "\n",
    "            Returns:\n",
    "                    os.path (str): Path to the final logdir\n",
    "    '''\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    project_logdir = os.path.join(root_logdir,project)\n",
    "    return os.path.join(project_logdir, run_id)\n",
    "\n",
    "\n",
    "#def lr_schedule(epoch):\n",
    "#  \"\"\"\n",
    "#  Returns a custom learning rate that decreases as epochs progress.\n",
    "#  \"\"\"\n",
    "#  learning_rate = 0.2\n",
    "#  if epoch > 10:\n",
    "#    learning_rate = 0.02\n",
    "#  if epoch > 20:\n",
    "#    learning_rate = 0.01\n",
    "#  if epoch > 50:\n",
    "#    learning_rate = 0.005\n",
    "#\n",
    "#  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "#  return learning_rate\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\n",
    "#lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 16s 158ms/step - loss: 1.7314 - accuracy: 0.3054 - val_loss: 1.5252 - val_accuracy: 0.3895\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 1.4834 - accuracy: 0.3624 - val_loss: 1.5076 - val_accuracy: 0.4002\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 6s 115ms/step - loss: 1.3873 - accuracy: 0.4025 - val_loss: 1.4657 - val_accuracy: 0.4126\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 6s 113ms/step - loss: 1.3297 - accuracy: 0.4284 - val_loss: 1.4189 - val_accuracy: 0.4014\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 6s 113ms/step - loss: 1.2862 - accuracy: 0.4514 - val_loss: 1.3776 - val_accuracy: 0.4391\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 6s 114ms/step - loss: 1.2487 - accuracy: 0.4733 - val_loss: 1.3498 - val_accuracy: 0.4528\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 1.2113 - accuracy: 0.4910 - val_loss: 1.3139 - val_accuracy: 0.4595\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 1.1756 - accuracy: 0.5124 - val_loss: 1.2686 - val_accuracy: 0.4655\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 1.1315 - accuracy: 0.5256 - val_loss: 1.2588 - val_accuracy: 0.4628\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 1.0812 - accuracy: 0.5517 - val_loss: 1.2005 - val_accuracy: 0.4956\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 1.0265 - accuracy: 0.5765 - val_loss: 1.1752 - val_accuracy: 0.5091\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.9665 - accuracy: 0.6046 - val_loss: 1.1571 - val_accuracy: 0.5189\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 0.9092 - accuracy: 0.6296 - val_loss: 1.1832 - val_accuracy: 0.5260\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.8451 - accuracy: 0.6532 - val_loss: 1.2098 - val_accuracy: 0.5336\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 0.7803 - accuracy: 0.6809 - val_loss: 1.2041 - val_accuracy: 0.5487\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 6s 127ms/step - loss: 0.7184 - accuracy: 0.7100 - val_loss: 1.2942 - val_accuracy: 0.5391\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 0.6593 - accuracy: 0.7304 - val_loss: 1.3668 - val_accuracy: 0.5423\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 6s 123ms/step - loss: 0.6024 - accuracy: 0.7602 - val_loss: 1.4170 - val_accuracy: 0.5517\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 0.5627 - accuracy: 0.7754 - val_loss: 1.5651 - val_accuracy: 0.5550\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.5054 - accuracy: 0.7955 - val_loss: 1.6129 - val_accuracy: 0.5582\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 6s 127ms/step - loss: 0.4591 - accuracy: 0.8172 - val_loss: 1.6818 - val_accuracy: 0.5619\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.4162 - accuracy: 0.8361 - val_loss: 1.7060 - val_accuracy: 0.5640\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.3891 - accuracy: 0.8493 - val_loss: 1.7619 - val_accuracy: 0.5675\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 0.3519 - accuracy: 0.8649 - val_loss: 1.7886 - val_accuracy: 0.5632\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.3111 - accuracy: 0.8811 - val_loss: 1.8824 - val_accuracy: 0.5711\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 0.2842 - accuracy: 0.8917 - val_loss: 1.8943 - val_accuracy: 0.5701\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 0.2625 - accuracy: 0.9039 - val_loss: 2.0616 - val_accuracy: 0.5617\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.2396 - accuracy: 0.9127 - val_loss: 2.1372 - val_accuracy: 0.5589\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.2177 - accuracy: 0.9214 - val_loss: 2.1892 - val_accuracy: 0.5749\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.2017 - accuracy: 0.9277 - val_loss: 2.3486 - val_accuracy: 0.5740\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.1860 - accuracy: 0.9367 - val_loss: 2.2395 - val_accuracy: 0.5686\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.1674 - accuracy: 0.9416 - val_loss: 2.3552 - val_accuracy: 0.5544\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.1619 - accuracy: 0.9433 - val_loss: 2.3822 - val_accuracy: 0.5696\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.1458 - accuracy: 0.9503 - val_loss: 2.4424 - val_accuracy: 0.5721\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.1353 - accuracy: 0.9528 - val_loss: 2.4944 - val_accuracy: 0.5696\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.1313 - accuracy: 0.9563 - val_loss: 2.6922 - val_accuracy: 0.5720\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 6s 124ms/step - loss: 0.1292 - accuracy: 0.9562 - val_loss: 2.6126 - val_accuracy: 0.5695\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 2.6462 - val_accuracy: 0.5713\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.1105 - accuracy: 0.9620 - val_loss: 2.6854 - val_accuracy: 0.5740\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.1094 - accuracy: 0.9650 - val_loss: 2.6757 - val_accuracy: 0.5709\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.0985 - accuracy: 0.9657 - val_loss: 2.7906 - val_accuracy: 0.5674\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.0903 - accuracy: 0.9685 - val_loss: 2.7171 - val_accuracy: 0.5609\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.0937 - accuracy: 0.9676 - val_loss: 2.8783 - val_accuracy: 0.5696\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.0919 - accuracy: 0.9674 - val_loss: 2.7716 - val_accuracy: 0.5685\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.0829 - accuracy: 0.9701 - val_loss: 2.8249 - val_accuracy: 0.5726\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.0825 - accuracy: 0.9696 - val_loss: 2.9105 - val_accuracy: 0.5698\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 6s 120ms/step - loss: 0.0806 - accuracy: 0.9706 - val_loss: 2.9017 - val_accuracy: 0.5646\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.0815 - accuracy: 0.9701 - val_loss: 2.9116 - val_accuracy: 0.5651\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 6s 119ms/step - loss: 0.0705 - accuracy: 0.9723 - val_loss: 3.0935 - val_accuracy: 0.5701\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 6s 121ms/step - loss: 0.0673 - accuracy: 0.9733 - val_loss: 3.1244 - val_accuracy: 0.5695\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    training_content_enc,\n",
    "    training_labels,\n",
    "    batch_size=512,      # small batch size are better but costs a lot of time\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(\n",
    "        validating_content_enc,\n",
    "        validating_labels_enc),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model_label_encoding_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Value Test (Validation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label for this validation set: [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoded label for this validation set: {validating_labels_enc[2486]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded value of the validation label: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Decoded value of the validation label: {encoder.inverse_transform(validating_labels_enc[2486])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models prediciton for this single validation data is: [0.25]\n"
     ]
    }
   ],
   "source": [
    "prediction_value = np.argmax(model.predict(validating_content_enc[np.newaxis , 2486]))\n",
    "print(f'Models prediciton for this single validation data is: {encoder.inverse_transform([prediction_value])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with all Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validating_content_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy is - 0.3624565899372101\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(validating_content_enc, validating_labels_enc, verbose=0)\n",
    "print(f'Models accuracy is - {evaluation[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f575d6a190>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Test File Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['id','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test data.\n",
    "test_content_enc = encode_text(tokenizer, test_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {test_content_enc.shape}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f886a0e7e4bdf7e8f253b33537ca1c5dcae8e086cc45ba5445b111bc8663c61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
