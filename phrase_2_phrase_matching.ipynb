{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "---Tensorflow is running with GPU Power now---\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\sample_submission.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\test.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#import mlflow\n",
    "#from mlflow import log_metric, log_param, log_artifacts\n",
    "#import mlflow.tensorflow\n",
    "#from mlflow import pyfunc\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(f'---Tensorflow is running with GPU Power now---')\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "\n",
    "\n",
    "random_state=42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n",
    "#kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "\n",
    "# change your local path here\n",
    "if iskaggle:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'input')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\n",
    "else:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(PHRASES_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\python-workspace\\\\phrase2phrase-match-ai\\\\data'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "CSV_FILE_CPC='titles.csv'\n",
    "CPC_PATH='input\\\\cpc-codes'\n",
    "\n",
    "def load_csv_data(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_csv_data_manuel(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "\n",
    "train = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\n",
    "test = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\n",
    "cpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(cpc_code.set_index('code'), on = 'context')\n",
    "test = test.join(cpc_code.set_index('code'), on = 'context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Attributes\n",
    "- id - a unique identifier for a pair of phrases\n",
    "- anchor - the first phrase\n",
    "- target - the second phrase\n",
    "- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
    "- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n",
    "\n",
    "\n",
    "## Score\n",
    "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
    "\n",
    "- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
    "- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
    "- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
    "- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
    "- 0.0 - Unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component composite coating              152\n",
       "sheet supply roller                      150\n",
       "source voltage                           140\n",
       "perfluoroalkyl group                     136\n",
       "el display                               135\n",
       "                                        ... \n",
       "plug nozzle                                2\n",
       "shannon                                    2\n",
       "dry coating composition1                   2\n",
       "peripheral nervous system stimulation      1\n",
       "conduct conducting material                1\n",
       "Name: anchor, Length: 733, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['anchor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anchor value has 733 different values. Lets look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition                    24\n",
       "data                           22\n",
       "metal                          22\n",
       "motor                          22\n",
       "assembly                       21\n",
       "                               ..\n",
       "switching switch over valve     1\n",
       "switching switch off valve      1\n",
       "switching over valve            1\n",
       "switching off valve             1\n",
       "wooden substrate                1\n",
       "Name: target, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target looks a little bit different. Here we have 29,340 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    12300\n",
       "0.25    11519\n",
       "0.00     7471\n",
       "0.75     4029\n",
       "1.00     1154\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEFCAYAAAABjYvXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASs0lEQVR4nO3df6zddX3H8edrrbCJmwW5QdYW24ROh2ZO7JDFZFlkgyLOkkUdxI3OdeuSoZvbMilbskYdCc5lTKJgGqmWxVAJU+kEZV3RmcXxo/wIE5Bxww9pg3K1BReNuup7f5xPdw+Xe9t7z7mc7+3u85Hc3O/3/f18z3mfk9O+zvf7/ZxzU1VIkha3n+i6AUlS9wwDSZJhIEkyDCRJGAaSJAwDSRKwtOsGBnXiiSfWqlWrum5Dko4qd91117eqamxq/agNg1WrVrFnz56u25Cko0qSx6ere5pIkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjiKP3QmPR9Wbb6p6xYAeOzy87puQYuMRwaSpCOHQZJtSZ5K8tW+2geTfC3JfUk+k2RZ37ZLk4wneSjJOX31da02nmRzX311kttb/VNJjpnHxydJmoXZHBl8Alg3pbYLeFVV/QLwX8ClAElOAy4AXtn2uSrJkiRLgI8A5wKnARe2sQAfAK6oqlOBA8DGoR6RJGnOjhgGVfVlYP+U2r9U1cG2ehuwoi2vB3ZU1Q+q6lFgHDij/YxX1SNV9UNgB7A+SYA3ADe0/bcD5w/3kCRJczUf1wx+D/h8W14OPNG3bW+rzVR/CfB0X7AcqkuSRmioMEjyV8BB4JPz084R729Tkj1J9kxMTIziLiVpURg4DJL8LvAm4O1VVa28D1jZN2xFq81U/zawLMnSKfVpVdXWqlpbVWvHxp7ztxkkSQMaKAySrAPeA7y5qr7Xt2kncEGSY5OsBtYAdwB3AmvazKFj6F1k3tlC5IvAW9r+G4AbB3sokqRBzWZq6XXAfwAvT7I3yUbgw8BPA7uS3JvkowBVdT9wPfAA8AXg4qr6Ubsm8E7gFuBB4Po2FuAS4M+SjNO7hnDNvD5CSdIRHfETyFV14TTlGf/DrqrLgMumqd8M3DxN/RF6s40kSR3xE8iSJMNAkmQYSJLwW0uF39QpySMDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYhZhkGRbkqeSfLWvdkKSXUkebr+Pb/UkuTLJeJL7kpzet8+GNv7hJBv66q9N8p9tnyuTZL4fpCTp8GZzZPAJYN2U2mZgd1WtAXa3dYBzgTXtZxNwNfTCA9gCvA44A9hyKEDamD/o22/qfUmSnmdHDIOq+jKwf0p5PbC9LW8Hzu+rX1s9twHLkpwMnAPsqqr9VXUA2AWsa9t+pqpuq6oCru27LUnSiAx6zeCkqnqyLX8DOKktLwee6Bu3t9UOV987TV2SNEJDX0Bu7+hrHno5oiSbkuxJsmdiYmIUdylJi8KgYfDNdoqH9vupVt8HrOwbt6LVDldfMU19WlW1tarWVtXasbGxAVuXJE01aBjsBA7NCNoA3NhXv6jNKjoTeKadTroFODvJ8e3C8dnALW3bd5Kc2WYRXdR3W5KkEVl6pAFJrgN+FTgxyV56s4IuB65PshF4HHhbG34z8EZgHPge8A6Aqtqf5P3AnW3c+6rq0EXpP6I3Y+mngM+3H0nSCB0xDKrqwhk2nTXN2AIunuF2tgHbpqnvAV51pD4kSc8fP4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJIYMgyR/muT+JF9Ncl2Sn0yyOsntScaTfCrJMW3ssW19vG1f1Xc7l7b6Q0nOGfIxSZLmaOAwSLIc+GNgbVW9ClgCXAB8ALiiqk4FDgAb2y4bgQOtfkUbR5LT2n6vBNYBVyVZMmhfkqS5G/Y00VLgp5IsBV4IPAm8Abihbd8OnN+W17d12vazkqTVd1TVD6rqUWAcOGPIviRJczBwGFTVPuDvgK/TC4FngLuAp6vqYBu2F1jelpcDT7R9D7bxL+mvT7OPJGkEhjlNdDy9d/WrgZ8FjqN3mud5k2RTkj1J9kxMTDyfdyVJi8owp4l+DXi0qiaq6n+ATwOvB5a100YAK4B9bXkfsBKgbX8x8O3++jT7PEtVba2qtVW1dmxsbIjWJUn9hgmDrwNnJnlhO/d/FvAA8EXgLW3MBuDGtryzrdO231pV1eoXtNlGq4E1wB1D9CVJmqOlRx4yvaq6PckNwN3AQeAeYCtwE7Ajyd+02jVtl2uAf0wyDuynN4OIqro/yfX0guQgcHFV/WjQviRJczdwGABU1RZgy5TyI0wzG6iqvg+8dYbbuQy4bJheJEmD8xPIkiTDQJJkGEiSMAwkSQx5AflotmrzTV23AMBjl5/XdQuS5JGBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJDBkGSZYluSHJ15I8mOSXk5yQZFeSh9vv49vYJLkyyXiS+5Kc3nc7G9r4h5NsGPZBSZLmZtgjgw8BX6iqVwCvBh4ENgO7q2oNsLutA5wLrGk/m4CrAZKcAGwBXgecAWw5FCCSpNEYOAySvBj4FeAagKr6YVU9DawHtrdh24Hz2/J64NrquQ1YluRk4BxgV1Xtr6oDwC5g3aB9SZLmbpgjg9XABPDxJPck+ViS44CTqurJNuYbwElteTnwRN/+e1ttprokaUSGCYOlwOnA1VX1GuC7TJ4SAqCqCqgh7uNZkmxKsifJnomJifm6WUla9IYJg73A3qq6va3fQC8cvtlO/9B+P9W27wNW9u2/otVmqj9HVW2tqrVVtXZsbGyI1iVJ/QYOg6r6BvBEkpe30lnAA8BO4NCMoA3AjW15J3BRm1V0JvBMO510C3B2kuPbheOzW02SNCJLh9z/XcAnkxwDPAK8g17AXJ9kI/A48LY29mbgjcA48L02lqran+T9wJ1t3Puqav+QfUmS5mCoMKiqe4G102w6a5qxBVw8w+1sA7YN04skaXB+AlmSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKYhzBIsiTJPUk+19ZXJ7k9yXiSTyU5ptWPbevjbfuqvtu4tNUfSnLOsD1JkuZmPo4M/gR4sG/9A8AVVXUqcADY2OobgQOtfkUbR5LTgAuAVwLrgKuSLJmHviRJszRUGCRZAZwHfKytB3gDcEMbsh04vy2vb+u07We18euBHVX1g6p6FBgHzhimL0nS3Ax7ZPAPwHuAH7f1lwBPV9XBtr4XWN6WlwNPALTtz7Tx/1efZh9J0ggsHXTHJG8Cnqqqu5L86rx1dPj73ARsAjjllFNGcZfSorVq801dtwDAY5ef13ULi8IwRwavB96c5DFgB73TQx8CliU5FDIrgH1teR+wEqBtfzHw7f76NPs8S1Vtraq1VbV2bGxsiNYlSf0GDoOqurSqVlTVKnoXgG+tqrcDXwTe0oZtAG5syzvbOm37rVVVrX5Bm220GlgD3DFoX5KkuRv4NNFhXALsSPI3wD3ANa1+DfCPScaB/fQChKq6P8n1wAPAQeDiqvrR89CXJGkG8xIGVfUl4Ett+RGmmQ1UVd8H3jrD/pcBl81HL5KkufMTyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEliiDBIsjLJF5M8kOT+JH/S6ick2ZXk4fb7+FZPkiuTjCe5L8npfbe1oY1/OMmG4R+WJGkuhjkyOAj8eVWdBpwJXJzkNGAzsLuq1gC72zrAucCa9rMJuBp64QFsAV4HnAFsORQgkqTRGDgMqurJqrq7Lf838CCwHFgPbG/DtgPnt+X1wLXVcxuwLMnJwDnArqraX1UHgF3AukH7kiTN3bxcM0iyCngNcDtwUlU92TZ9AzipLS8HnujbbW+rzVSXJI3I0GGQ5EXAPwHvrqrv9G+rqgJq2Pvou69NSfYk2TMxMTFfNytJi95QYZDkBfSC4JNV9elW/mY7/UP7/VSr7wNW9u2+otVmqj9HVW2tqrVVtXZsbGyY1iVJfYaZTRTgGuDBqvr7vk07gUMzgjYAN/bVL2qzis4Enmmnk24Bzk5yfLtwfHarSZJGZOkQ+74e+B3gP5Pc22p/CVwOXJ9kI/A48La27WbgjcA48D3gHQBVtT/J+4E727j3VdX+IfqSJM3RwGFQVf8OZIbNZ00zvoCLZ7itbcC2QXuRJA3HTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJInhvo5CkhaFVZtv6roFAB67/Lzn7bY9MpAkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJLKAwSLIuyUNJxpNs7rofSVpMFkQYJFkCfAQ4FzgNuDDJad12JUmLx4IIA+AMYLyqHqmqHwI7gPUd9yRJi8ZCCYPlwBN963tbTZI0AqmqrnsgyVuAdVX1+239d4DXVdU7p4zbBGxqqy8HHhppo891IvCtjntYKHwuJvlcTPK5mLRQnouXVdXY1OLSLjqZxj5gZd/6ilZ7lqraCmwdVVNHkmRPVa3tuo+FwOdiks/FJJ+LSQv9uVgop4nuBNYkWZ3kGOACYGfHPUnSorEgjgyq6mCSdwK3AEuAbVV1f8dtSdKisSDCAKCqbgZu7rqPOVowp6wWAJ+LST4Xk3wuJi3o52JBXECWJHVroVwzkCR1yDCQJBkGg0hyQpITuu5DkuaLYTBLSU5JsiPJBHA7cEeSp1ptVcftdapNCf7NJK/ouhctHL4uji6Gwex9CvgM8NKqWlNVpwInA5+l911Ki0aSz/YtrwduBX4DuDHJ73bUVieS/F7f8ooku5M8neQrSX6uy95GzdfFcyU5Kcnp7eekrvs5HGcTzVKSh6tqzVy3/X+U5J6qek1b/grw9qp6NMmJwO6qenW3HY5Okrur6vS2fD3wr8DH6H3R4jur6qwu+xslXxeTkvwi8FHgxUx+m8IK4Gngj6rq7m46m9mC+ZzBUeCuJFcB25n8Ur2VwAbgns666kb/O4ilVfUoQFV9K8mPO+ppIfi5qnpbW/5Mkr/utJvR83Ux6RPAH1bV7f3FJGcCHwcWXDAaBrN3EbAReC+T36i6F/hn4JqumurIq5N8BwhwbJKTq+rJ9lUiSzrubdRWJLmS3nMxluQFVfU/bdsLOuyrC74uJh03NQgAquq2JMd10dCRGAaz1P7OwtXtZ1Grqpn+Yb8Q+MNR9rIA/EXf8h7gRcCBJC9lkX2/lq+LZ/l8kpuAa3n2mYSLgC901tVheM1gHiR5U1V9rus+JC0cSc6ld+3o0JmEfcDO9tU7C45hMA+SvLeqtnTdx6gkWQl8kN6L/PPABw+dGkny2ao6v8P2FozF9iYhyX7g08B1wK3lfy5HFaeWzkGSVyS5JMmV7eeSJD+/mIKg2QZ8CXgXvem1/5bkJW3by7pqagH6pa4bGLEJ4F7gfcDeJB9qF0zVp/2RrgXHawazlOQS4EJ6nym4o5VXANcl2VFVl3fW3OiNVdVH2/K7kvw28OUkb+bZM0oWhfahqulOByy2NwnfraoPAx9Ocgq9v0tyVZJlwI6q+stOu1s40nUD0/E00Swl+S/glX0zRQ7VjwHuX2SfM7gfeG1Vfb+v9mv05lUfV1Und9bciE15k7C3lVfQ+49wUb1J6P+cwZT6K4Dfqqr3dtDWgpPkHVX18a77mMowmKUkXwPOqarHp9RfBvxLVb28m85GL8mfAndX1b9Nqb8G+Nuq+vVuOhs93yRMSvL3VfVnXfex0CX5elWd0nUfUxkGs5RkHfBh4GEmp4qdApxK75OmC3K6mJ5fvknQdJLcN9Mmeh9OPHaU/cyGYTAHSX4COINnnxu+s6p+1F1XC8sinEHjm4RZWISvi28C5wAHpm4CvlJVPzv6rg7PC8hzUFU/Bm7ruo8F7peARfOPvqq+0L6QzjcJh7eoXhf0HuuLqureqRuSfGnk3cyCRwYayGFm0DzYXVfqmq+Lo5efM9CctRk0O+gd8t7RfkJvmu3mLntTd3xdHN08MtCcOYNG0/F1cXTzyECD+DEw3QWwk9s2LU6+Lo5iXkDWIN4N7E4y7QyarppS596Nr4ujlqeJNBCn2Wo6vi6OXoaBJMlrBpIkw0CShGEgScIwkCRhGEiSgP8FiFLL3enR6sgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['score'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abatement</th>\n",
       "      <th>A47</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A61</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">wiring trough</th>\n",
       "      <th>F16</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H02</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wood article</th>\n",
       "      <th>B05</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B44</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  target  score  title  section  class  subclass  \\\n",
       "anchor        context                                                       \n",
       "abatement     A47      21      21     21     21       21     21         0   \n",
       "              A61       3       3      3      3        3      3         0   \n",
       "              A62       1       1      1      1        1      1         0   \n",
       "              C01       1       1      1      1        1      1         0   \n",
       "              F16       1       1      1      1        1      1         0   \n",
       "...                    ..     ...    ...    ...      ...    ...       ...   \n",
       "wiring trough F16      27      27     27     27       27     27         0   \n",
       "              H02      18      18     18     18       18     18         0   \n",
       "wood article  B05      28      28     28     28       28     28         0   \n",
       "              B27       1       1      1      1        1      1         0   \n",
       "              B44      27      27     27     27       27     27         0   \n",
       "\n",
       "                       group  main_group  \n",
       "anchor        context                     \n",
       "abatement     A47          0           0  \n",
       "              A61          0           0  \n",
       "              A62          0           0  \n",
       "              C01          0           0  \n",
       "              F16          0           0  \n",
       "...                      ...         ...  \n",
       "wiring trough F16          0           0  \n",
       "              H02          0           0  \n",
       "wood article  B05          0           0  \n",
       "              B27          0           0  \n",
       "              B44          0           0  \n",
       "\n",
       "[1699 rows x 9 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['anchor', 'context']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corpus'] = train['anchor'] + ' ' + train['target']\n",
    "train['corpus_w_context'] = train['corpus'] + ' ' +  train['context']\n",
    "train['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']\n",
    "\n",
    "test['corpus'] = test['anchor'] + ' ' + test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifing the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['id','score']].copy()\n",
    "X = train[['id','anchor','target','context', 'corpus', 'corpus_w_context', 'corpus_w_full_context']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training_target - list: 25531\n",
      "Length of training_content - list: 25531\n",
      "Length of training_content_w_context - list: 25531\n",
      "Length of training_content_full - list: 25531\n",
      "Length of validating_content - list: 10942\n",
      "Length of validating_content_w_context - list: 10942\n",
      "Length of validating_content_full - list: 10942\n",
      "Length of test_content - list: 36\n"
     ]
    }
   ],
   "source": [
    "training_target = X_train['target']\n",
    "print(f'Length of training_target - list: {len(training_target)}')\n",
    "\n",
    "training_content = X_train['corpus']\n",
    "print(f'Length of training_content - list: {len(training_content)}')\n",
    "\n",
    "training_content_w_context = X_train['corpus_w_context']\n",
    "print(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n",
    "\n",
    "training_content_full = X_train['corpus_w_full_context']\n",
    "print(f'Length of training_content_full - list: {len(training_content_full)}')\n",
    "\n",
    "\n",
    "validating_content = X_val['corpus']\n",
    "print(f'Length of validating_content - list: {len(validating_content)}')\n",
    "\n",
    "validating_content_w_context = X_val['corpus_w_context']\n",
    "print(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n",
    "\n",
    "validating_content_full = X_val['corpus_w_full_context']\n",
    "print(f'Length of validating_content_full - list: {len(validating_content_full)}')\n",
    "\n",
    "\n",
    "test_content = test['corpus']\n",
    "print(f'Length of test_content - list: {len(test_content)}')\n",
    "\n",
    "\n",
    "training_labels = y_train['score']\n",
    "validating_labels = y_val['score']\n",
    "\n",
    "training_labels = np.array(training_labels)\n",
    "validating_labels = np.array(validating_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train['score'])\n",
    "\n",
    "training_labels = encoder.transform(training_labels)\n",
    "validating_labels_enc = encoder.transform(validating_labels)\n",
    "\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "validating_labels_enc = validating_labels_enc.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Encoding and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # downloading nltk punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document, alpha=True):\n",
    "    '''Extracing words from a sentence or full text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: str\n",
    "        Text that needs to be tokenized by nltk word_tokenize.\n",
    "    alpha: bool\n",
    "        Keep only letters or not. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of words from the given text.\n",
    "    '''\n",
    "    if alpha == True:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "            if any(c.isalpha() for c in word)\n",
    "        )\n",
    "    else:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    content = []\n",
    "    for doc in docs:\n",
    "        content.append(extract_words(doc))\n",
    "    return content\n",
    "\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(sequences, maxlen=length)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(training_content_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding params\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_line_length = max_length(training_content_full)\n",
    "word_count = tokenizer.word_counts\n",
    "word_index = tokenizer.word_index\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set (encoded): (25531, 51)\n",
      "Shape validating set (encoded): (10942, 51)\n",
      "Vocabulary size: 7750\n",
      "Max line lenght: 51\n"
     ]
    }
   ],
   "source": [
    "training_content_enc = encode_text(tokenizer, training_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {training_content_enc.shape}')\n",
    "\n",
    "validating_content_enc = encode_text(tokenizer, validating_content, max_line_length)\n",
    "print(f'Shape validating set (encoded): {validating_content_enc.shape}')\n",
    "\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'Max line lenght: {max_line_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.getcwd(), \"data\\\\glove.6B\\\\glove.6B.300d.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file ,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n",
    "\n",
    "According to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7245 words (504 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = vocab_size #+ 1 # + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "lr = 0.01\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new Embedding Layer\n",
    "Now loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Embedding(    \n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        input_length=max_line_length,\n",
    "        mask_zero=False,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False),\n",
    "    tf.keras.layers.SpatialDropout1D(0.5),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5), ## mal mit einbauen \n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    #tf.keras.layers.Dense(16),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Activation('relu'),\n",
    "    #tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(5, activation='softmax' )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n",
    "                #optimizer=keras.optimizers.SGD(momentum=mmt, nesterov=False),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 51, 300)           2325000   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, 51, 300)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 200)              320800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               25728     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,683,725\n",
      "Trainable params: 357,877\n",
      "Non-trainable params: 2,325,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logging structure function\n",
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "def get_run_logdir(root_logdir, project):\n",
    "    '''\n",
    "    Returns logdir to the Tensorboard log for a specific project.\n",
    "\n",
    "            Parameters:\n",
    "                    root_logdir (str) : basic logdir from Tensorboard\n",
    "                    project (str): projectname that will be logged in TB\n",
    "\n",
    "            Returns:\n",
    "                    os.path (str): Path to the final logdir\n",
    "    '''\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    project_logdir = os.path.join(root_logdir,project)\n",
    "    return os.path.join(project_logdir, run_id)\n",
    "\n",
    "\n",
    "#def lr_schedule(epoch):\n",
    "#  \"\"\"\n",
    "#  Returns a custom learning rate that decreases as epochs progress.\n",
    "#  \"\"\"\n",
    "#  learning_rate = 0.2\n",
    "#  if epoch > 10:\n",
    "#    learning_rate = 0.02\n",
    "#  if epoch > 20:\n",
    "#    learning_rate = 0.01\n",
    "#  if epoch > 50:\n",
    "#    learning_rate = 0.005\n",
    "#\n",
    "#  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "#  return learning_rate\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\n",
    "#lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1419/1419 [==============================] - 34s 22ms/step - loss: 1.4866 - accuracy: 0.3219 - val_loss: 1.3842 - val_accuracy: 0.3640\n",
      "Epoch 2/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.4032 - accuracy: 0.3595 - val_loss: 1.3754 - val_accuracy: 0.3805\n",
      "Epoch 3/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.3836 - accuracy: 0.3659 - val_loss: 1.3647 - val_accuracy: 0.3692\n",
      "Epoch 4/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.3686 - accuracy: 0.3825 - val_loss: 1.3506 - val_accuracy: 0.3853\n",
      "Epoch 5/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.3534 - accuracy: 0.3939 - val_loss: 1.3200 - val_accuracy: 0.4207\n",
      "Epoch 6/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.3345 - accuracy: 0.4109 - val_loss: 1.3046 - val_accuracy: 0.4228\n",
      "Epoch 7/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.3189 - accuracy: 0.4215 - val_loss: 1.2987 - val_accuracy: 0.4373\n",
      "Epoch 8/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.3029 - accuracy: 0.4395 - val_loss: 1.2744 - val_accuracy: 0.4482\n",
      "Epoch 9/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.2867 - accuracy: 0.4501 - val_loss: 1.2573 - val_accuracy: 0.4605\n",
      "Epoch 10/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.2692 - accuracy: 0.4576 - val_loss: 1.2397 - val_accuracy: 0.4719\n",
      "Epoch 11/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.2575 - accuracy: 0.4631 - val_loss: 1.2367 - val_accuracy: 0.4706\n",
      "Epoch 12/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.2431 - accuracy: 0.4742 - val_loss: 1.2266 - val_accuracy: 0.4782\n",
      "Epoch 13/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.2278 - accuracy: 0.4811 - val_loss: 1.2087 - val_accuracy: 0.4831\n",
      "Epoch 14/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.2171 - accuracy: 0.4862 - val_loss: 1.2107 - val_accuracy: 0.4850\n",
      "Epoch 15/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.2072 - accuracy: 0.4902 - val_loss: 1.1947 - val_accuracy: 0.4925\n",
      "Epoch 16/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.1991 - accuracy: 0.4952 - val_loss: 1.1915 - val_accuracy: 0.4911\n",
      "Epoch 17/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1904 - accuracy: 0.4992 - val_loss: 1.1931 - val_accuracy: 0.4964\n",
      "Epoch 18/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.1795 - accuracy: 0.5048 - val_loss: 1.1823 - val_accuracy: 0.4973\n",
      "Epoch 19/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1719 - accuracy: 0.5108 - val_loss: 1.1820 - val_accuracy: 0.4963\n",
      "Epoch 20/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.1610 - accuracy: 0.5121 - val_loss: 1.1703 - val_accuracy: 0.5005\n",
      "Epoch 21/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.1524 - accuracy: 0.5198 - val_loss: 1.1736 - val_accuracy: 0.5032\n",
      "Epoch 22/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1554 - accuracy: 0.5115 - val_loss: 1.1766 - val_accuracy: 0.5069\n",
      "Epoch 23/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.1362 - accuracy: 0.5258 - val_loss: 1.1661 - val_accuracy: 0.5080\n",
      "Epoch 24/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.1441 - accuracy: 0.5238 - val_loss: 1.1605 - val_accuracy: 0.5151\n",
      "Epoch 25/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.1313 - accuracy: 0.5297 - val_loss: 1.1582 - val_accuracy: 0.5109\n",
      "Epoch 26/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1276 - accuracy: 0.5276 - val_loss: 1.1598 - val_accuracy: 0.5155\n",
      "Epoch 27/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1226 - accuracy: 0.5299 - val_loss: 1.1637 - val_accuracy: 0.5135\n",
      "Epoch 28/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1258 - accuracy: 0.5312 - val_loss: 1.1490 - val_accuracy: 0.5169\n",
      "Epoch 29/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.1148 - accuracy: 0.5366 - val_loss: 1.1508 - val_accuracy: 0.5192\n",
      "Epoch 30/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.1115 - accuracy: 0.5353 - val_loss: 1.1499 - val_accuracy: 0.5148\n",
      "Epoch 31/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.1083 - accuracy: 0.5392 - val_loss: 1.1584 - val_accuracy: 0.5111\n",
      "Epoch 32/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.1040 - accuracy: 0.5408 - val_loss: 1.1489 - val_accuracy: 0.5200\n",
      "Epoch 33/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0956 - accuracy: 0.5470 - val_loss: 1.1518 - val_accuracy: 0.5217\n",
      "Epoch 34/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0984 - accuracy: 0.5409 - val_loss: 1.1401 - val_accuracy: 0.5215\n",
      "Epoch 35/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0942 - accuracy: 0.5483 - val_loss: 1.1416 - val_accuracy: 0.5214\n",
      "Epoch 36/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0909 - accuracy: 0.5482 - val_loss: 1.1469 - val_accuracy: 0.5229\n",
      "Epoch 37/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0889 - accuracy: 0.5460 - val_loss: 1.1450 - val_accuracy: 0.5240\n",
      "Epoch 38/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0836 - accuracy: 0.5486 - val_loss: 1.1347 - val_accuracy: 0.5269\n",
      "Epoch 39/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0816 - accuracy: 0.5514 - val_loss: 1.1426 - val_accuracy: 0.5293\n",
      "Epoch 40/200\n",
      "1419/1419 [==============================] - 28s 19ms/step - loss: 1.0784 - accuracy: 0.5540 - val_loss: 1.1355 - val_accuracy: 0.5240\n",
      "Epoch 41/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0783 - accuracy: 0.5513 - val_loss: 1.1364 - val_accuracy: 0.5282\n",
      "Epoch 42/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0749 - accuracy: 0.5537 - val_loss: 1.1450 - val_accuracy: 0.5252\n",
      "Epoch 43/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0686 - accuracy: 0.5567 - val_loss: 1.1367 - val_accuracy: 0.5303\n",
      "Epoch 44/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0622 - accuracy: 0.5614 - val_loss: 1.1383 - val_accuracy: 0.5269\n",
      "Epoch 45/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0662 - accuracy: 0.5575 - val_loss: 1.1302 - val_accuracy: 0.5276\n",
      "Epoch 46/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0674 - accuracy: 0.5571 - val_loss: 1.1388 - val_accuracy: 0.5286\n",
      "Epoch 47/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0573 - accuracy: 0.5659 - val_loss: 1.1439 - val_accuracy: 0.5271\n",
      "Epoch 48/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0614 - accuracy: 0.5607 - val_loss: 1.1265 - val_accuracy: 0.5315\n",
      "Epoch 49/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0615 - accuracy: 0.5632 - val_loss: 1.1370 - val_accuracy: 0.5295\n",
      "Epoch 50/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0590 - accuracy: 0.5603 - val_loss: 1.1343 - val_accuracy: 0.5248\n",
      "Epoch 51/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0553 - accuracy: 0.5572 - val_loss: 1.1381 - val_accuracy: 0.5246\n",
      "Epoch 52/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0467 - accuracy: 0.5666 - val_loss: 1.1435 - val_accuracy: 0.5280\n",
      "Epoch 53/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0525 - accuracy: 0.5655 - val_loss: 1.1382 - val_accuracy: 0.5280\n",
      "Epoch 54/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0489 - accuracy: 0.5653 - val_loss: 1.1351 - val_accuracy: 0.5331\n",
      "Epoch 55/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0484 - accuracy: 0.5670 - val_loss: 1.1403 - val_accuracy: 0.5313\n",
      "Epoch 56/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0511 - accuracy: 0.5649 - val_loss: 1.1346 - val_accuracy: 0.5338\n",
      "Epoch 57/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.2214 - accuracy: 0.4753 - val_loss: 1.2967 - val_accuracy: 0.4297\n",
      "Epoch 58/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0840 - accuracy: 0.5502 - val_loss: 1.1219 - val_accuracy: 0.5324\n",
      "Epoch 59/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0529 - accuracy: 0.5632 - val_loss: 1.1317 - val_accuracy: 0.5312\n",
      "Epoch 60/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0407 - accuracy: 0.5720 - val_loss: 1.1289 - val_accuracy: 0.5334\n",
      "Epoch 61/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0518 - accuracy: 0.5677 - val_loss: 1.1279 - val_accuracy: 0.5333\n",
      "Epoch 62/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0376 - accuracy: 0.5718 - val_loss: 1.1321 - val_accuracy: 0.5337\n",
      "Epoch 63/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0390 - accuracy: 0.5717 - val_loss: 1.1314 - val_accuracy: 0.5325\n",
      "Epoch 64/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0394 - accuracy: 0.5704 - val_loss: 1.1297 - val_accuracy: 0.5368\n",
      "Epoch 65/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0417 - accuracy: 0.5713 - val_loss: 1.1259 - val_accuracy: 0.5365\n",
      "Epoch 66/200\n",
      "1419/1419 [==============================] - 32s 23ms/step - loss: 1.0363 - accuracy: 0.5749 - val_loss: 1.1283 - val_accuracy: 0.5350\n",
      "Epoch 67/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 1.0357 - accuracy: 0.5720 - val_loss: 1.1296 - val_accuracy: 0.5328\n",
      "Epoch 68/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0374 - accuracy: 0.5733 - val_loss: 1.1364 - val_accuracy: 0.5326\n",
      "Epoch 69/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0288 - accuracy: 0.5728 - val_loss: 1.1407 - val_accuracy: 0.5345\n",
      "Epoch 70/200\n",
      "1419/1419 [==============================] - 32s 23ms/step - loss: 1.0312 - accuracy: 0.5758 - val_loss: 1.1336 - val_accuracy: 0.5316\n",
      "Epoch 71/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0520 - accuracy: 0.5687 - val_loss: 1.1410 - val_accuracy: 0.5285\n",
      "Epoch 72/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0327 - accuracy: 0.5777 - val_loss: 1.1225 - val_accuracy: 0.5331\n",
      "Epoch 73/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0290 - accuracy: 0.5738 - val_loss: 1.1297 - val_accuracy: 0.5323\n",
      "Epoch 74/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0354 - accuracy: 0.5735 - val_loss: 1.1300 - val_accuracy: 0.5306\n",
      "Epoch 75/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0310 - accuracy: 0.5724 - val_loss: 1.1267 - val_accuracy: 0.5357\n",
      "Epoch 76/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0311 - accuracy: 0.5749 - val_loss: 1.1323 - val_accuracy: 0.5312\n",
      "Epoch 77/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0207 - accuracy: 0.5846 - val_loss: 1.1450 - val_accuracy: 0.5357\n",
      "Epoch 78/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0215 - accuracy: 0.5792 - val_loss: 1.1358 - val_accuracy: 0.5383\n",
      "Epoch 79/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0193 - accuracy: 0.5786 - val_loss: 1.1428 - val_accuracy: 0.5364\n",
      "Epoch 80/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0213 - accuracy: 0.5790 - val_loss: 1.1448 - val_accuracy: 0.5374\n",
      "Epoch 81/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0167 - accuracy: 0.5822 - val_loss: 1.1446 - val_accuracy: 0.5339\n",
      "Epoch 82/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0247 - accuracy: 0.5773 - val_loss: 1.1255 - val_accuracy: 0.5352\n",
      "Epoch 83/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0213 - accuracy: 0.5820 - val_loss: 1.1295 - val_accuracy: 0.5374\n",
      "Epoch 84/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0202 - accuracy: 0.5802 - val_loss: 1.1349 - val_accuracy: 0.5323\n",
      "Epoch 85/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0150 - accuracy: 0.5856 - val_loss: 1.1382 - val_accuracy: 0.5343\n",
      "Epoch 86/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0153 - accuracy: 0.5821 - val_loss: 1.1323 - val_accuracy: 0.5357\n",
      "Epoch 87/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0175 - accuracy: 0.5826 - val_loss: 1.1279 - val_accuracy: 0.5388\n",
      "Epoch 88/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0168 - accuracy: 0.5831 - val_loss: 1.1391 - val_accuracy: 0.5337\n",
      "Epoch 89/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0057 - accuracy: 0.5834 - val_loss: 1.1305 - val_accuracy: 0.5344\n",
      "Epoch 90/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0173 - accuracy: 0.5847 - val_loss: 1.1212 - val_accuracy: 0.5406\n",
      "Epoch 91/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0109 - accuracy: 0.5822 - val_loss: 1.1324 - val_accuracy: 0.5377\n",
      "Epoch 92/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0152 - accuracy: 0.5798 - val_loss: 1.1279 - val_accuracy: 0.5374\n",
      "Epoch 93/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0142 - accuracy: 0.5801 - val_loss: 1.1295 - val_accuracy: 0.5372\n",
      "Epoch 94/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0051 - accuracy: 0.5851 - val_loss: 1.1250 - val_accuracy: 0.5354\n",
      "Epoch 95/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0147 - accuracy: 0.5854 - val_loss: 1.1317 - val_accuracy: 0.5391\n",
      "Epoch 96/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0073 - accuracy: 0.5895 - val_loss: 1.1227 - val_accuracy: 0.5324\n",
      "Epoch 97/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0101 - accuracy: 0.5845 - val_loss: 1.1315 - val_accuracy: 0.5333\n",
      "Epoch 98/200\n",
      "1419/1419 [==============================] - 32s 22ms/step - loss: 1.0056 - accuracy: 0.5883 - val_loss: 1.1327 - val_accuracy: 0.5378\n",
      "Epoch 99/200\n",
      "1419/1419 [==============================] - 32s 23ms/step - loss: 1.0025 - accuracy: 0.5894 - val_loss: 1.1293 - val_accuracy: 0.5367\n",
      "Epoch 100/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0007 - accuracy: 0.5918 - val_loss: 1.1346 - val_accuracy: 0.5350\n",
      "Epoch 101/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0094 - accuracy: 0.5847 - val_loss: 1.1332 - val_accuracy: 0.5353\n",
      "Epoch 102/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.0033 - accuracy: 0.5855 - val_loss: 1.1314 - val_accuracy: 0.5336\n",
      "Epoch 103/200\n",
      "1419/1419 [==============================] - 32s 22ms/step - loss: 1.0029 - accuracy: 0.5882 - val_loss: 1.1294 - val_accuracy: 0.5360\n",
      "Epoch 104/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 0.9948 - accuracy: 0.5923 - val_loss: 1.1325 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9956 - accuracy: 0.5942 - val_loss: 1.1412 - val_accuracy: 0.5349\n",
      "Epoch 106/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0122 - accuracy: 0.5826 - val_loss: 1.1282 - val_accuracy: 0.5374\n",
      "Epoch 107/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 1.0042 - accuracy: 0.5891 - val_loss: 1.1365 - val_accuracy: 0.5399\n",
      "Epoch 108/200\n",
      "1419/1419 [==============================] - 32s 22ms/step - loss: 0.9947 - accuracy: 0.5942 - val_loss: 1.1440 - val_accuracy: 0.5409\n",
      "Epoch 109/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9960 - accuracy: 0.5909 - val_loss: 1.1327 - val_accuracy: 0.5410\n",
      "Epoch 110/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0084 - accuracy: 0.5873 - val_loss: 1.1307 - val_accuracy: 0.5416\n",
      "Epoch 111/200\n",
      "1419/1419 [==============================] - 32s 22ms/step - loss: 1.0005 - accuracy: 0.5898 - val_loss: 1.1279 - val_accuracy: 0.5397\n",
      "Epoch 112/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0073 - accuracy: 0.5852 - val_loss: 1.1262 - val_accuracy: 0.5428\n",
      "Epoch 113/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9976 - accuracy: 0.5881 - val_loss: 1.1307 - val_accuracy: 0.5394\n",
      "Epoch 114/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 0.9992 - accuracy: 0.5939 - val_loss: 1.1344 - val_accuracy: 0.5393\n",
      "Epoch 115/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0077 - accuracy: 0.5898 - val_loss: 1.1270 - val_accuracy: 0.5419\n",
      "Epoch 116/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9968 - accuracy: 0.5949 - val_loss: 1.1373 - val_accuracy: 0.5425\n",
      "Epoch 117/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 1.0048 - accuracy: 0.5912 - val_loss: 1.1394 - val_accuracy: 0.5389\n",
      "Epoch 118/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0044 - accuracy: 0.5872 - val_loss: 1.1285 - val_accuracy: 0.5380\n",
      "Epoch 119/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9880 - accuracy: 0.5941 - val_loss: 1.1283 - val_accuracy: 0.5374\n",
      "Epoch 120/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9902 - accuracy: 0.5911 - val_loss: 1.1289 - val_accuracy: 0.5409\n",
      "Epoch 121/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.1428 - accuracy: 0.5271 - val_loss: 1.1327 - val_accuracy: 0.5443\n",
      "Epoch 122/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 1.0024 - accuracy: 0.5910 - val_loss: 1.1273 - val_accuracy: 0.5350\n",
      "Epoch 123/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9928 - accuracy: 0.5930 - val_loss: 1.1389 - val_accuracy: 0.5395\n",
      "Epoch 124/200\n",
      "1419/1419 [==============================] - 26s 19ms/step - loss: 0.9987 - accuracy: 0.5918 - val_loss: 1.1317 - val_accuracy: 0.5387\n",
      "Epoch 125/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9912 - accuracy: 0.5964 - val_loss: 1.1340 - val_accuracy: 0.5323\n",
      "Epoch 126/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9906 - accuracy: 0.5950 - val_loss: 1.1425 - val_accuracy: 0.5375\n",
      "Epoch 127/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9914 - accuracy: 0.5975 - val_loss: 1.1347 - val_accuracy: 0.5401\n",
      "Epoch 128/200\n",
      "1419/1419 [==============================] - 28s 19ms/step - loss: 0.9917 - accuracy: 0.5911 - val_loss: 1.1529 - val_accuracy: 0.5259\n",
      "Epoch 129/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9927 - accuracy: 0.5934 - val_loss: 1.1367 - val_accuracy: 0.5319\n",
      "Epoch 130/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9937 - accuracy: 0.5957 - val_loss: 1.1329 - val_accuracy: 0.5349\n",
      "Epoch 131/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9960 - accuracy: 0.5898 - val_loss: 1.1226 - val_accuracy: 0.5394\n",
      "Epoch 132/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9904 - accuracy: 0.5928 - val_loss: 1.1395 - val_accuracy: 0.5346\n",
      "Epoch 133/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9918 - accuracy: 0.5936 - val_loss: 1.1334 - val_accuracy: 0.5362\n",
      "Epoch 134/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9935 - accuracy: 0.5953 - val_loss: 1.1254 - val_accuracy: 0.5379\n",
      "Epoch 135/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9843 - accuracy: 0.5971 - val_loss: 1.1395 - val_accuracy: 0.5361\n",
      "Epoch 136/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9830 - accuracy: 0.5995 - val_loss: 1.1381 - val_accuracy: 0.5388\n",
      "Epoch 137/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9933 - accuracy: 0.5966 - val_loss: 1.1152 - val_accuracy: 0.5421\n",
      "Epoch 138/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9890 - accuracy: 0.5963 - val_loss: 1.1296 - val_accuracy: 0.5395\n",
      "Epoch 139/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9908 - accuracy: 0.5969 - val_loss: 1.1227 - val_accuracy: 0.5386\n",
      "Epoch 140/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9954 - accuracy: 0.5932 - val_loss: 1.1329 - val_accuracy: 0.5428\n",
      "Epoch 141/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9887 - accuracy: 0.5974 - val_loss: 1.1310 - val_accuracy: 0.5394\n",
      "Epoch 142/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9906 - accuracy: 0.5941 - val_loss: 1.1375 - val_accuracy: 0.5366\n",
      "Epoch 143/200\n",
      "1419/1419 [==============================] - 28s 19ms/step - loss: 0.9896 - accuracy: 0.5943 - val_loss: 1.1300 - val_accuracy: 0.5398\n",
      "Epoch 144/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9899 - accuracy: 0.5960 - val_loss: 1.1286 - val_accuracy: 0.5418\n",
      "Epoch 145/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 1.1150 - accuracy: 0.5376 - val_loss: 1.1306 - val_accuracy: 0.5387\n",
      "Epoch 146/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9913 - accuracy: 0.5932 - val_loss: 1.1323 - val_accuracy: 0.5361\n",
      "Epoch 147/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9900 - accuracy: 0.5938 - val_loss: 1.1308 - val_accuracy: 0.5399\n",
      "Epoch 148/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9915 - accuracy: 0.5941 - val_loss: 1.1288 - val_accuracy: 0.5377\n",
      "Epoch 149/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0202 - accuracy: 0.5853 - val_loss: 1.1368 - val_accuracy: 0.5372\n",
      "Epoch 150/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9873 - accuracy: 0.5983 - val_loss: 1.1325 - val_accuracy: 0.5379\n",
      "Epoch 151/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9898 - accuracy: 0.5996 - val_loss: 1.1288 - val_accuracy: 0.5372\n",
      "Epoch 152/200\n",
      "1419/1419 [==============================] - 28s 19ms/step - loss: 0.9865 - accuracy: 0.5958 - val_loss: 1.1312 - val_accuracy: 0.5372\n",
      "Epoch 153/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9933 - accuracy: 0.5949 - val_loss: 1.1315 - val_accuracy: 0.5326\n",
      "Epoch 154/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9851 - accuracy: 0.5990 - val_loss: 1.1388 - val_accuracy: 0.5354\n",
      "Epoch 155/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9849 - accuracy: 0.5966 - val_loss: 1.1373 - val_accuracy: 0.5368\n",
      "Epoch 156/200\n",
      "1419/1419 [==============================] - 26s 19ms/step - loss: 0.9848 - accuracy: 0.5958 - val_loss: 1.1325 - val_accuracy: 0.5366\n",
      "Epoch 157/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9868 - accuracy: 0.5926 - val_loss: 1.1371 - val_accuracy: 0.5361\n",
      "Epoch 158/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9912 - accuracy: 0.5970 - val_loss: 1.1305 - val_accuracy: 0.5395\n",
      "Epoch 159/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9796 - accuracy: 0.5986 - val_loss: 1.1483 - val_accuracy: 0.5413\n",
      "Epoch 160/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9768 - accuracy: 0.6041 - val_loss: 1.1374 - val_accuracy: 0.5419\n",
      "Epoch 161/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9794 - accuracy: 0.5986 - val_loss: 1.1433 - val_accuracy: 0.5398\n",
      "Epoch 162/200\n",
      "1419/1419 [==============================] - 26s 19ms/step - loss: 0.9861 - accuracy: 0.5982 - val_loss: 1.1454 - val_accuracy: 0.5366\n",
      "Epoch 163/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9864 - accuracy: 0.5948 - val_loss: 1.1311 - val_accuracy: 0.5390\n",
      "Epoch 164/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9823 - accuracy: 0.5963 - val_loss: 1.1336 - val_accuracy: 0.5391\n",
      "Epoch 165/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9865 - accuracy: 0.5973 - val_loss: 1.1305 - val_accuracy: 0.5412\n",
      "Epoch 166/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9827 - accuracy: 0.5970 - val_loss: 1.1246 - val_accuracy: 0.5427\n",
      "Epoch 167/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9832 - accuracy: 0.6000 - val_loss: 1.1303 - val_accuracy: 0.5395\n",
      "Epoch 168/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9836 - accuracy: 0.5990 - val_loss: 1.1452 - val_accuracy: 0.5408\n",
      "Epoch 169/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9899 - accuracy: 0.5988 - val_loss: 1.1456 - val_accuracy: 0.5377\n",
      "Epoch 170/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9838 - accuracy: 0.5995 - val_loss: 1.1313 - val_accuracy: 0.5379\n",
      "Epoch 171/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9813 - accuracy: 0.6022 - val_loss: 1.1308 - val_accuracy: 0.5402\n",
      "Epoch 172/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9792 - accuracy: 0.5997 - val_loss: 1.1418 - val_accuracy: 0.5397\n",
      "Epoch 173/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9762 - accuracy: 0.6042 - val_loss: 1.1445 - val_accuracy: 0.5430\n",
      "Epoch 174/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 1.0036 - accuracy: 0.5897 - val_loss: 1.1257 - val_accuracy: 0.5391\n",
      "Epoch 175/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9822 - accuracy: 0.6030 - val_loss: 1.1320 - val_accuracy: 0.5433\n",
      "Epoch 176/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9692 - accuracy: 0.6092 - val_loss: 1.1322 - val_accuracy: 0.5375\n",
      "Epoch 177/200\n",
      "1419/1419 [==============================] - 26s 19ms/step - loss: 0.9788 - accuracy: 0.6025 - val_loss: 1.1326 - val_accuracy: 0.5371\n",
      "Epoch 178/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9806 - accuracy: 0.5997 - val_loss: 1.1255 - val_accuracy: 0.5424\n",
      "Epoch 179/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9827 - accuracy: 0.6016 - val_loss: 1.1357 - val_accuracy: 0.5393\n",
      "Epoch 180/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9788 - accuracy: 0.5977 - val_loss: 1.1281 - val_accuracy: 0.5420\n",
      "Epoch 181/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9810 - accuracy: 0.6000 - val_loss: 1.1361 - val_accuracy: 0.5387\n",
      "Epoch 182/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9750 - accuracy: 0.6029 - val_loss: 1.1293 - val_accuracy: 0.5400\n",
      "Epoch 183/200\n",
      "1419/1419 [==============================] - 27s 19ms/step - loss: 0.9768 - accuracy: 0.6021 - val_loss: 1.1246 - val_accuracy: 0.5484\n",
      "Epoch 184/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 0.9806 - accuracy: 0.6022 - val_loss: 1.1510 - val_accuracy: 0.5353\n",
      "Epoch 185/200\n",
      "1419/1419 [==============================] - 26s 18ms/step - loss: 1.0750 - accuracy: 0.5603 - val_loss: 1.1370 - val_accuracy: 0.5377\n",
      "Epoch 186/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9840 - accuracy: 0.5953 - val_loss: 1.1386 - val_accuracy: 0.5406\n",
      "Epoch 187/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9763 - accuracy: 0.6003 - val_loss: 1.1259 - val_accuracy: 0.5432\n",
      "Epoch 188/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9718 - accuracy: 0.6070 - val_loss: 1.1343 - val_accuracy: 0.5395\n",
      "Epoch 189/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9777 - accuracy: 0.6011 - val_loss: 1.1345 - val_accuracy: 0.5368\n",
      "Epoch 190/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 0.9855 - accuracy: 0.6000 - val_loss: 1.1347 - val_accuracy: 0.5451\n",
      "Epoch 191/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9712 - accuracy: 0.6052 - val_loss: 1.1424 - val_accuracy: 0.5390\n",
      "Epoch 192/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9767 - accuracy: 0.6038 - val_loss: 1.1393 - val_accuracy: 0.5370\n",
      "Epoch 193/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9693 - accuracy: 0.6074 - val_loss: 1.1419 - val_accuracy: 0.5441\n",
      "Epoch 194/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9808 - accuracy: 0.5982 - val_loss: 1.1412 - val_accuracy: 0.5427\n",
      "Epoch 195/200\n",
      "1419/1419 [==============================] - 31s 22ms/step - loss: 0.9703 - accuracy: 0.6036 - val_loss: 1.1452 - val_accuracy: 0.5412\n",
      "Epoch 196/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9728 - accuracy: 0.6049 - val_loss: 1.1411 - val_accuracy: 0.5424\n",
      "Epoch 197/200\n",
      "1419/1419 [==============================] - 30s 21ms/step - loss: 0.9801 - accuracy: 0.6010 - val_loss: 1.1334 - val_accuracy: 0.5414\n",
      "Epoch 198/200\n",
      "1419/1419 [==============================] - 29s 20ms/step - loss: 0.9818 - accuracy: 0.6019 - val_loss: 1.1341 - val_accuracy: 0.5359\n",
      "Epoch 199/200\n",
      "1419/1419 [==============================] - 28s 20ms/step - loss: 0.9678 - accuracy: 0.6066 - val_loss: 1.1404 - val_accuracy: 0.5356\n",
      "Epoch 200/200\n",
      "1419/1419 [==============================] - 29s 21ms/step - loss: 0.9703 - accuracy: 0.6077 - val_loss: 1.1501 - val_accuracy: 0.5302\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "history = model.fit(\n",
    "    training_content_enc,\n",
    "    training_labels,\n",
    "    batch_size=18,      # small batch size are better but costs a lot of time\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(\n",
    "        validating_content_enc,\n",
    "        validating_labels_enc),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model_label_encoding_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Value Test (Validation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label for this validation set: [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoded label for this validation set: {validating_labels_enc[2486]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded value of the validation label: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Decoded value of the validation label: {encoder.inverse_transform(validating_labels_enc[2486])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models prediciton for this single validation data is: [0.75]\n"
     ]
    }
   ],
   "source": [
    "prediction_value = np.argmax(model.predict(validating_content_enc[np.newaxis , 2486]))\n",
    "print(f'Models prediciton for this single validation data is: {encoder.inverse_transform([prediction_value])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with all Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validating_content_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy is - 0.5301589965820312 %\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(validating_content_enc, validating_labels_enc, verbose=0)\n",
    "print(f'Models accuracy is - {evaluation[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a0bf340340>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Test File Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['id','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test data.\n",
    "test_content_enc = encode_text(tokenizer, test_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {test_content_enc.shape}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f886a0e7e4bdf7e8f253b33537ca1c5dcae8e086cc45ba5445b111bc8663c61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
