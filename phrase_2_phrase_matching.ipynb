{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "---Tensorflow is running with GPU Power now---\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\sample_submission.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\test.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#import mlflow\n",
    "#from mlflow import log_metric, log_param, log_artifacts\n",
    "#import mlflow.tensorflow\n",
    "#from mlflow import pyfunc\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(f'---Tensorflow is running with GPU Power now---')\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "\n",
    "\n",
    "random_state=42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n",
    "#kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "\n",
    "# change your local path here\n",
    "if iskaggle:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'input')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\n",
    "else:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(PHRASES_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\python-workspace\\\\phrase2phrase-match-ai\\\\data'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "CSV_FILE_CPC='titles.csv'\n",
    "CPC_PATH='input\\\\cpc-codes'\n",
    "\n",
    "def load_csv_data(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_csv_data_manuel(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "\n",
    "train = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\n",
    "test = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\n",
    "cpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(cpc_code.set_index('code'), on = 'context')\n",
    "test = test.join(cpc_code.set_index('code'), on = 'context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Attributes\n",
    "- id - a unique identifier for a pair of phrases\n",
    "- anchor - the first phrase\n",
    "- target - the second phrase\n",
    "- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
    "- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n",
    "\n",
    "\n",
    "## Score\n",
    "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
    "\n",
    "- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
    "- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
    "- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
    "- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
    "- 0.0 - Unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component composite coating              152\n",
       "sheet supply roller                      150\n",
       "source voltage                           140\n",
       "perfluoroalkyl group                     136\n",
       "el display                               135\n",
       "                                        ... \n",
       "plug nozzle                                2\n",
       "shannon                                    2\n",
       "dry coating composition1                   2\n",
       "peripheral nervous system stimulation      1\n",
       "conduct conducting material                1\n",
       "Name: anchor, Length: 733, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['anchor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anchor value has 733 different values. Lets look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition                    24\n",
       "data                           22\n",
       "metal                          22\n",
       "motor                          22\n",
       "assembly                       21\n",
       "                               ..\n",
       "switching switch over valve     1\n",
       "switching switch off valve      1\n",
       "switching over valve            1\n",
       "switching off valve             1\n",
       "wooden substrate                1\n",
       "Name: target, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target looks a little bit different. Here we have 29,340 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    12300\n",
       "0.25    11519\n",
       "0.00     7471\n",
       "0.75     4029\n",
       "1.00     1154\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['score'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abatement</th>\n",
       "      <th>A47</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A61</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">wiring trough</th>\n",
       "      <th>F16</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H02</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wood article</th>\n",
       "      <th>B05</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B44</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  target  score  title  section  class  subclass  \\\n",
       "anchor        context                                                       \n",
       "abatement     A47      21      21     21     21       21     21         0   \n",
       "              A61       3       3      3      3        3      3         0   \n",
       "              A62       1       1      1      1        1      1         0   \n",
       "              C01       1       1      1      1        1      1         0   \n",
       "              F16       1       1      1      1        1      1         0   \n",
       "...                    ..     ...    ...    ...      ...    ...       ...   \n",
       "wiring trough F16      27      27     27     27       27     27         0   \n",
       "              H02      18      18     18     18       18     18         0   \n",
       "wood article  B05      28      28     28     28       28     28         0   \n",
       "              B27       1       1      1      1        1      1         0   \n",
       "              B44      27      27     27     27       27     27         0   \n",
       "\n",
       "                       group  main_group  \n",
       "anchor        context                     \n",
       "abatement     A47          0           0  \n",
       "              A61          0           0  \n",
       "              A62          0           0  \n",
       "              C01          0           0  \n",
       "              F16          0           0  \n",
       "...                      ...         ...  \n",
       "wiring trough F16          0           0  \n",
       "              H02          0           0  \n",
       "wood article  B05          0           0  \n",
       "              B27          0           0  \n",
       "              B44          0           0  \n",
       "\n",
       "[1699 rows x 9 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['anchor', 'context']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corpus'] = train['anchor'] + ' ' + train['target']\n",
    "train['corpus_w_context'] = train['corpus'] + ' ' +  train['context']\n",
    "train['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']\n",
    "\n",
    "test['corpus'] = test['anchor'] + ' ' + test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifing the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['id','score']].copy()\n",
    "X = train[['id','anchor','target','context', 'corpus', 'corpus_w_context', 'corpus_w_full_context']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training_target - list: 25531\n",
      "Length of training_content - list: 25531\n",
      "Length of training_content_w_context - list: 25531\n",
      "Length of training_content_full - list: 25531\n",
      "Length of validating_content - list: 10942\n",
      "Length of validating_content_w_context - list: 10942\n",
      "Length of validating_content_full - list: 10942\n",
      "Length of test_content - list: 36\n"
     ]
    }
   ],
   "source": [
    "training_target = X_train['target']\n",
    "print(f'Length of training_target - list: {len(training_target)}')\n",
    "\n",
    "training_content = X_train['corpus']\n",
    "print(f'Length of training_content - list: {len(training_content)}')\n",
    "\n",
    "training_content_w_context = X_train['corpus_w_context']\n",
    "print(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n",
    "\n",
    "training_content_full = X_train['corpus_w_full_context']\n",
    "print(f'Length of training_content_full - list: {len(training_content_full)}')\n",
    "\n",
    "\n",
    "validating_content = X_val['corpus']\n",
    "print(f'Length of validating_content - list: {len(validating_content)}')\n",
    "\n",
    "validating_content_w_context = X_val['corpus_w_context']\n",
    "print(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n",
    "\n",
    "validating_content_full = X_val['corpus_w_full_context']\n",
    "print(f'Length of validating_content_full - list: {len(validating_content_full)}')\n",
    "\n",
    "\n",
    "test_content = test['corpus']\n",
    "print(f'Length of test_content - list: {len(test_content)}')\n",
    "\n",
    "\n",
    "training_labels = y_train['score']\n",
    "validating_labels = y_val['score']\n",
    "\n",
    "training_labels = np.array(training_labels)\n",
    "validating_labels = np.array(validating_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train['score'])\n",
    "\n",
    "training_labels = encoder.transform(training_labels)\n",
    "validating_labels_enc = encoder.transform(validating_labels)\n",
    "\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "validating_labels_enc = validating_labels_enc.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Encoding and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # downloading nltk punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document, alpha=True):\n",
    "    '''Extracing words from a sentence or full text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: str\n",
    "        Text that needs to be tokenized by nltk word_tokenize.\n",
    "    alpha: bool\n",
    "        Keep only letters or not. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of words from the given text.\n",
    "    '''\n",
    "    if alpha == True:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "            if any(c.isalpha() for c in word)\n",
    "        )\n",
    "    else:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    content = []\n",
    "    for doc in docs:\n",
    "        content.append(extract_words(doc))\n",
    "    return content\n",
    "\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(sequences, maxlen=length)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(training_content_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_line_length = max_length(training_content_full)\n",
    "word_count = tokenizer.word_counts\n",
    "word_index = tokenizer.word_index\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set (encoded): (25531, 51)\n",
      "Shape validating set (encoded): (10942, 51)\n",
      "Vocabulary size: 7750\n",
      "Max line lenght: 51\n"
     ]
    }
   ],
   "source": [
    "training_content_enc = encode_text(tokenizer, training_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {training_content_enc.shape}')\n",
    "\n",
    "validating_content_enc = encode_text(tokenizer, validating_content, max_line_length)\n",
    "print(f'Shape validating set (encoded): {validating_content_enc.shape}')\n",
    "\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'Max line lenght: {max_line_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.getcwd(), \"data\\\\glove.6B\\\\glove.6B.300d.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file ,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n",
    "\n",
    "According to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7245 words (504 misses)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300 # according to the pretrained network\n",
    "hits = 0\n",
    "misses = 0\n",
    "lr = 0.01\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new Embedding Layer\n",
    "Now loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    keras.layers.Embedding(    \n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        input_shape = [None],\n",
    "        input_length=max_line_length,\n",
    "        mask_zero=True,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False),\n",
    "    #keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.GRU(300, return_sequences=True),\n",
    "    keras.layers.GRU(300),\n",
    "    #keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5), ## mal mit einbauen \n",
    "    keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(32),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    #keras.layers.Dense(16),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Activation('relu'),\n",
    "    #keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(5, activation='softmax' )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 300)         2325000   \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, None, 300)         541800    \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 300)               541800    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               38528     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,459,341\n",
      "Trainable params: 1,133,485\n",
      "Non-trainable params: 2,325,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logging structure function\n",
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "def get_run_logdir(root_logdir, project):\n",
    "    '''\n",
    "    Returns logdir to the Tensorboard log for a specific project.\n",
    "\n",
    "            Parameters:\n",
    "                    root_logdir (str) : basic logdir from Tensorboard\n",
    "                    project (str): projectname that will be logged in TB\n",
    "\n",
    "            Returns:\n",
    "                    os.path (str): Path to the final logdir\n",
    "    '''\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    project_logdir = os.path.join(root_logdir,project)\n",
    "    return os.path.join(project_logdir, run_id)\n",
    "\n",
    "\n",
    "#def lr_schedule(epoch):\n",
    "#  \"\"\"\n",
    "#  Returns a custom learning rate that decreases as epochs progress.\n",
    "#  \"\"\"\n",
    "#  learning_rate = 0.2\n",
    "#  if epoch > 10:\n",
    "#    learning_rate = 0.02\n",
    "#  if epoch > 20:\n",
    "#    learning_rate = 0.01\n",
    "#  if epoch > 50:\n",
    "#    learning_rate = 0.005\n",
    "#\n",
    "#  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "#  return learning_rate\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\n",
    "#lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 28s 430ms/step - loss: 1.5800 - accuracy: 0.3056 - val_loss: 1.5308 - val_accuracy: 0.3350\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 1.4389 - accuracy: 0.3382 - val_loss: 1.4935 - val_accuracy: 0.3482\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 1.4099 - accuracy: 0.3565 - val_loss: 1.4581 - val_accuracy: 0.3675\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 1.3884 - accuracy: 0.3732 - val_loss: 1.4252 - val_accuracy: 0.3870\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 1.3645 - accuracy: 0.3900 - val_loss: 1.3700 - val_accuracy: 0.4138\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.3430 - accuracy: 0.4077 - val_loss: 1.3451 - val_accuracy: 0.4125\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 20s 399ms/step - loss: 1.3137 - accuracy: 0.4278 - val_loss: 1.3121 - val_accuracy: 0.4302\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.2991 - accuracy: 0.4361 - val_loss: 1.2976 - val_accuracy: 0.4328\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 1.2760 - accuracy: 0.4547 - val_loss: 1.2948 - val_accuracy: 0.4390\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 20s 400ms/step - loss: 1.2485 - accuracy: 0.4687 - val_loss: 1.2736 - val_accuracy: 0.4463\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 19s 387ms/step - loss: 1.2301 - accuracy: 0.4791 - val_loss: 1.2674 - val_accuracy: 0.4507\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 19s 389ms/step - loss: 1.1987 - accuracy: 0.4938 - val_loss: 1.2503 - val_accuracy: 0.4601\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 19s 386ms/step - loss: 1.1700 - accuracy: 0.5091 - val_loss: 1.2543 - val_accuracy: 0.4675\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 19s 386ms/step - loss: 1.1342 - accuracy: 0.5227 - val_loss: 1.2426 - val_accuracy: 0.4769\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 1.0901 - accuracy: 0.5398 - val_loss: 1.2302 - val_accuracy: 0.4873\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 1.0467 - accuracy: 0.5585 - val_loss: 1.2775 - val_accuracy: 0.4876\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 1.0058 - accuracy: 0.5762 - val_loss: 1.2790 - val_accuracy: 0.4915\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 0.9618 - accuracy: 0.5956 - val_loss: 1.2508 - val_accuracy: 0.5149\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 20s 399ms/step - loss: 0.9078 - accuracy: 0.6170 - val_loss: 1.2876 - val_accuracy: 0.5148\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 0.8642 - accuracy: 0.6347 - val_loss: 1.2926 - val_accuracy: 0.5212\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 0.8111 - accuracy: 0.6549 - val_loss: 1.3629 - val_accuracy: 0.5318\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 21s 414ms/step - loss: 0.7608 - accuracy: 0.6805 - val_loss: 1.3535 - val_accuracy: 0.5344\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 20s 405ms/step - loss: 0.7241 - accuracy: 0.6959 - val_loss: 1.4239 - val_accuracy: 0.5425\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 0.6751 - accuracy: 0.7149 - val_loss: 1.5346 - val_accuracy: 0.5449\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.6242 - accuracy: 0.7393 - val_loss: 1.6058 - val_accuracy: 0.5517\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 0.5803 - accuracy: 0.7584 - val_loss: 1.6963 - val_accuracy: 0.5574\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.5428 - accuracy: 0.7802 - val_loss: 1.6896 - val_accuracy: 0.5348\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 0.5032 - accuracy: 0.7952 - val_loss: 1.8736 - val_accuracy: 0.5597\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 20s 399ms/step - loss: 0.4788 - accuracy: 0.8060 - val_loss: 1.9531 - val_accuracy: 0.5597\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 19s 383ms/step - loss: 0.4327 - accuracy: 0.8253 - val_loss: 2.1283 - val_accuracy: 0.5591\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 0.4082 - accuracy: 0.8402 - val_loss: 2.1435 - val_accuracy: 0.5521\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 0.3762 - accuracy: 0.8520 - val_loss: 2.2636 - val_accuracy: 0.5605\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 0.3510 - accuracy: 0.8642 - val_loss: 2.5172 - val_accuracy: 0.5538\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 0.3402 - accuracy: 0.8725 - val_loss: 2.4068 - val_accuracy: 0.5614\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 20s 400ms/step - loss: 0.3060 - accuracy: 0.8852 - val_loss: 2.4141 - val_accuracy: 0.5584\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 0.2933 - accuracy: 0.8904 - val_loss: 2.5228 - val_accuracy: 0.5571\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 20s 399ms/step - loss: 0.2792 - accuracy: 0.8976 - val_loss: 2.4687 - val_accuracy: 0.5613\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 20s 399ms/step - loss: 0.2567 - accuracy: 0.9085 - val_loss: 2.9955 - val_accuracy: 0.5667\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 0.2496 - accuracy: 0.9096 - val_loss: 2.7153 - val_accuracy: 0.5643\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 0.2379 - accuracy: 0.9143 - val_loss: 2.7726 - val_accuracy: 0.5565\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 0.2251 - accuracy: 0.9203 - val_loss: 2.9735 - val_accuracy: 0.5638\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 19s 386ms/step - loss: 0.2158 - accuracy: 0.9255 - val_loss: 2.9253 - val_accuracy: 0.5607\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 19s 388ms/step - loss: 0.1961 - accuracy: 0.9296 - val_loss: 3.0648 - val_accuracy: 0.5673\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 20s 402ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 3.0904 - val_accuracy: 0.5583\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 0.1818 - accuracy: 0.9372 - val_loss: 2.9780 - val_accuracy: 0.5607\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 0.1727 - accuracy: 0.9414 - val_loss: 3.1469 - val_accuracy: 0.5635\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 0.1682 - accuracy: 0.9403 - val_loss: 3.0493 - val_accuracy: 0.5586\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.1667 - accuracy: 0.9447 - val_loss: 3.2102 - val_accuracy: 0.5663\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 0.1609 - accuracy: 0.9458 - val_loss: 3.3325 - val_accuracy: 0.5664\n",
      "Epoch 50/50\n",
      "26/50 [==============>...............] - ETA: 8s - loss: 0.1470 - accuracy: 0.9500"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    training_content_enc,\n",
    "    training_labels,\n",
    "    batch_size=512,      # small batch size are better but costs a lot of time\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(\n",
    "        validating_content_enc,\n",
    "        validating_labels_enc),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model_label_encoding_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Value Test (Validation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label for this validation set: [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoded label for this validation set: {validating_labels_enc[2486]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded value of the validation label: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Decoded value of the validation label: {encoder.inverse_transform(validating_labels_enc[2486])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models prediciton for this single validation data is: [0.75]\n"
     ]
    }
   ],
   "source": [
    "prediction_value = np.argmax(model.predict(validating_content_enc[np.newaxis , 2486]))\n",
    "print(f'Models prediciton for this single validation data is: {encoder.inverse_transform([prediction_value])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with all Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validating_content_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy is - 0.5724730491638184\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(validating_content_enc, validating_labels_enc, verbose=0)\n",
    "print(f'Models accuracy is - {evaluation[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cdb8ad9c70>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Test File Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['id','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test data.\n",
    "test_content_enc = encode_text(tokenizer, test_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {test_content_enc.shape}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f886a0e7e4bdf7e8f253b33537ca1c5dcae8e086cc45ba5445b111bc8663c61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
