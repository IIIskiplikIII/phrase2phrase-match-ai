{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "---Tensorflow is running with GPU Power now---\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\sample_submission.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\test.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "from transformers import BertTokenizer, TFDebertaModel\n",
    "\n",
    "#import mlflow\n",
    "#from mlflow import log_metric, log_param, log_artifacts\n",
    "#import mlflow.tensorflow\n",
    "#from mlflow import pyfunc\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(f'---Tensorflow is running with GPU Power now---')\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "\n",
    "\n",
    "random_state=42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n",
    "#kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "\n",
    "# change your local path here\n",
    "if iskaggle:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'input')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\n",
    "else:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(PHRASES_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\python-workspace\\\\phrase2phrase-match-ai\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of loaded trainset: 36473\n",
      "Length of loaded testset: 36\n",
      "Length of loaded competition file: 36\n",
      "Length of loaded cpc_codeset: 260476\n"
     ]
    }
   ],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "CSV_FILE_COMF='sample_submission.csv'\n",
    "CSV_FILE_CPC='titles.csv'\n",
    "CPC_PATH='input\\\\cpc-codes'\n",
    "\n",
    "def load_csv_data(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_csv_data_manuel(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "\n",
    "train = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\n",
    "test = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\n",
    "competition_file = load_csv_data(PHRASES_PATH,CSV_FILE_COMF)\n",
    "cpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)\n",
    "\n",
    "\n",
    "print(f'Length of loaded trainset: {len(train)}')\n",
    "print(f'Length of loaded testset: {len(test)}')\n",
    "print(f'Length of loaded competition file: {len(competition_file)}')\n",
    "print(f'Length of loaded cpc_codeset: {len(cpc_code)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(cpc_code.set_index('code'), on = 'context')\n",
    "test = test.join(cpc_code.set_index('code'), on = 'context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Attributes\n",
    "- id - a unique identifier for a pair of phrases\n",
    "- anchor - the first phrase\n",
    "- target - the second phrase\n",
    "- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
    "- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n",
    "\n",
    "\n",
    "## Score\n",
    "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
    "\n",
    "- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
    "- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
    "- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
    "- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
    "- 0.0 - Unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component composite coating              152\n",
       "sheet supply roller                      150\n",
       "source voltage                           140\n",
       "perfluoroalkyl group                     136\n",
       "el display                               135\n",
       "                                        ... \n",
       "plug nozzle                                2\n",
       "shannon                                    2\n",
       "dry coating composition1                   2\n",
       "peripheral nervous system stimulation      1\n",
       "conduct conducting material                1\n",
       "Name: anchor, Length: 733, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['anchor'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anchor value has 733 different values. Lets look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition                    24\n",
       "data                           22\n",
       "metal                          22\n",
       "motor                          22\n",
       "assembly                       21\n",
       "                               ..\n",
       "switching switch over valve     1\n",
       "switching switch off valve      1\n",
       "switching over valve            1\n",
       "switching off valve             1\n",
       "wooden substrate                1\n",
       "Name: target, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target looks a little bit different. Here we have 29,340 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    12300\n",
       "0.25    11519\n",
       "0.00     7471\n",
       "0.75     4029\n",
       "1.00     1154\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False).sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abatement</th>\n",
       "      <th>A47</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A61</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">wiring trough</th>\n",
       "      <th>F16</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H02</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wood article</th>\n",
       "      <th>B05</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B44</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  target  score  title  section  class  subclass  \\\n",
       "anchor        context                                                       \n",
       "abatement     A47      21      21     21     21       21     21         0   \n",
       "              A61       3       3      3      3        3      3         0   \n",
       "              A62       1       1      1      1        1      1         0   \n",
       "              C01       1       1      1      1        1      1         0   \n",
       "              F16       1       1      1      1        1      1         0   \n",
       "...                    ..     ...    ...    ...      ...    ...       ...   \n",
       "wiring trough F16      27      27     27     27       27     27         0   \n",
       "              H02      18      18     18     18       18     18         0   \n",
       "wood article  B05      28      28     28     28       28     28         0   \n",
       "              B27       1       1      1      1        1      1         0   \n",
       "              B44      27      27     27     27       27     27         0   \n",
       "\n",
       "                       group  main_group  \n",
       "anchor        context                     \n",
       "abatement     A47          0           0  \n",
       "              A61          0           0  \n",
       "              A62          0           0  \n",
       "              C01          0           0  \n",
       "              F16          0           0  \n",
       "...                      ...         ...  \n",
       "wiring trough F16          0           0  \n",
       "              H02          0           0  \n",
       "wood article  B05          0           0  \n",
       "              B27          0           0  \n",
       "              B44          0           0  \n",
       "\n",
       "[1699 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['anchor', 'context']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing cpc text \n",
    "# Build a function around it ?????? !!!!!!!!!!!!!!!!!\n",
    "train['title'] = train.title.apply(lambda text: text.split(';'))\n",
    "train['title'] = train.title.apply(lambda context: ' '.join(context))\n",
    "\n",
    "#train.title.apply(lambda text: (lambda text: text.split(';'))(' '.join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corpus'] = train['anchor'] + ' ' + train['target']\n",
    "train['corpus_w_context'] = train['corpus'] + ' ' +  train['context']\n",
    "train['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']\n",
    "\n",
    "test['corpus'] = test['anchor'] + ' ' + test['target']\n",
    "test['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifing the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['id','score']].copy()\n",
    "X = train[['id','anchor','target','context', 'corpus', 'title', 'corpus_w_context', 'corpus_w_full_context']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training_target - list: 25531\n",
      "Length of training_content - list: 25531\n",
      "Length of training_content_w_context - list: 25531\n",
      "Length of training_content_full - list: 25531\n",
      "Length of validating_content - list: 10942\n",
      "Length of validating_content_w_context - list: 10942\n",
      "Length of validating_content_full - list: 10942\n",
      "Length of test_content - list: 36\n",
      "Length of test_content_full - list: 36\n"
     ]
    }
   ],
   "source": [
    "training_target = X_train['target']\n",
    "print(f'Length of training_target - list: {len(training_target)}')\n",
    "\n",
    "training_content = X_train['corpus']\n",
    "print(f'Length of training_content - list: {len(training_content)}')\n",
    "\n",
    "training_content_w_context = X_train['corpus_w_context']\n",
    "print(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n",
    "\n",
    "training_content_full = X_train['corpus_w_full_context']\n",
    "print(f'Length of training_content_full - list: {len(training_content_full)}')\n",
    "\n",
    "\n",
    "validating_content = X_val['corpus']\n",
    "print(f'Length of validating_content - list: {len(validating_content)}')\n",
    "\n",
    "validating_content_w_context = X_val['corpus_w_context']\n",
    "print(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n",
    "\n",
    "validating_content_full = X_val['corpus_w_full_context']\n",
    "print(f'Length of validating_content_full - list: {len(validating_content_full)}')\n",
    "\n",
    "\n",
    "test_content = test['corpus']\n",
    "print(f'Length of test_content - list: {len(test_content)}')\n",
    "\n",
    "test_content_full = test['corpus_w_full_context']\n",
    "print(f'Length of test_content_full - list: {len(test_content_full)}')\n",
    "\n",
    "training_labels = y_train['score']\n",
    "validating_labels = y_val['score']\n",
    "\n",
    "training_labels = np.asarray(training_labels)\n",
    "validating_labels = np.asarray(validating_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train['score'])\n",
    "\n",
    "training_labels = encoder.transform(training_labels)\n",
    "validating_labels = encoder.transform(validating_labels)\n",
    "\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "validating_labels = validating_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Encoding and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document, alpha=True):\n",
    "    '''Extracing words from a sentence or full text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: str\n",
    "        Text that needs to be tokenized by nltk word_tokenize.\n",
    "    alpha: bool\n",
    "        Keep only letters or not. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of words from the given text.\n",
    "    '''\n",
    "    if alpha == True:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "            if any(c.isalpha() for c in word)\n",
    "        )\n",
    "    else:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    content = []\n",
    "    for doc in docs:\n",
    "        content.append(extract_words(doc))\n",
    "    return content\n",
    "\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(sequences, maxlen=length)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(training_content_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_line_length = max_length(training_content_full)\n",
    "word_count = tokenizer.word_counts\n",
    "word_index = tokenizer.word_index\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set (encoded): (25531, 51)\n",
      "Shape validating set (encoded): (10942, 51)\n",
      "Vocabulary size: 7750\n",
      "Max line lenght: 51\n"
     ]
    }
   ],
   "source": [
    "training_content_enc = encode_text(tokenizer, training_content_full, max_line_length)\n",
    "print(f'Shape training set (encoded): {training_content_enc.shape}')\n",
    "\n",
    "validating_content_enc = encode_text(tokenizer, validating_content_full, max_line_length)\n",
    "print(f'Shape validating set (encoded): {validating_content_enc.shape}')\n",
    "\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'Max line lenght: {max_line_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development Based on Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.getcwd(), \"data\\\\glove.6B\\\\glove.6B.300d.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file ,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params for the Glove based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main params for the model\n",
    "embedding_dim = 300 # according to the pretrained network\n",
    "hits = 0\n",
    "misses = 0\n",
    "lr = 0.000008\n",
    "batch_size = 512\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n",
    "\n",
    "According to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7245 words (504 misses)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new Embedding Layer\n",
    "Now loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    keras.layers.Embedding(    \n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        input_shape = [None],\n",
    "        input_length=max_line_length,\n",
    "        mask_zero=True,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False),\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    #keras.layers.LayerNormalization(),\n",
    "    #Bidirectional(keras.layers.LSTM(300, return_sequences=True)),\n",
    "    #keras.layers.LSTM(300),\n",
    "    #keras.layers.MultiHeadAttention(key_dim=254, num_heads=4, value_dim=20, dropout=0.25),\n",
    "    keras.layers.LSTM(300, return_sequences=True),\n",
    "    keras.layers.LSTM(300),\n",
    "    #keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dropout(0.5), \n",
    "    #keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax' )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2325000   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, None, 300)        0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 300)         721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,770,105\n",
      "Trainable params: 1,444,505\n",
      "Non-trainable params: 2,325,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Tensorboard logging structure function\n",
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "def get_run_logdir(root_logdir, project):\n",
    "    '''\n",
    "    Returns logdir to the Tensorboard log for a specific project.\n",
    "\n",
    "            Parameters:\n",
    "                    root_logdir (str) : basic logdir from Tensorboard\n",
    "                    project (str): projectname that will be logged in TB\n",
    "\n",
    "            Returns:\n",
    "                    os.path (str): Path to the final logdir\n",
    "    '''\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    project_logdir = os.path.join(root_logdir,project)\n",
    "    return os.path.join(project_logdir, run_id)\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  decay = 1\n",
    "  init_lr = lr \n",
    "  learning_rate = init_lr * (1 / (1 + decay * epoch))\n",
    "\n",
    "  ##learning_rate = lr\n",
    "  ##if epoch < 1:\n",
    "  ##  learning_rate = 0.0000008\n",
    "  ##if epoch >= 2:\n",
    "  ##  learning_rate = 0.0000006\n",
    "\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\n",
    "tensorboard_callback_deberta = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase_deberta\"), histogram_freq=1)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f7f11f6e50>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([lr_scheduler(e) for e in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 26s 401ms/step - loss: 1.6401 - accuracy: 0.3201 - val_loss: 1.5247 - val_accuracy: 0.3522\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 1.4410 - accuracy: 0.3567 - val_loss: 1.4983 - val_accuracy: 0.3599\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.3816 - accuracy: 0.3817 - val_loss: 1.4925 - val_accuracy: 0.3388\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 1.3577 - accuracy: 0.3944 - val_loss: 1.4865 - val_accuracy: 0.3625\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 18s 363ms/step - loss: 1.3438 - accuracy: 0.4066 - val_loss: 1.4833 - val_accuracy: 0.3463\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 1.3295 - accuracy: 0.4169 - val_loss: 1.4579 - val_accuracy: 0.3743\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 1.3149 - accuracy: 0.4283 - val_loss: 1.4484 - val_accuracy: 0.3923\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.2963 - accuracy: 0.4389 - val_loss: 1.3998 - val_accuracy: 0.3992\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 18s 361ms/step - loss: 1.2794 - accuracy: 0.4484 - val_loss: 1.3562 - val_accuracy: 0.4113\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 1.2608 - accuracy: 0.4590 - val_loss: 1.3548 - val_accuracy: 0.4128\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 1.2453 - accuracy: 0.4665 - val_loss: 1.3104 - val_accuracy: 0.4174\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 18s 371ms/step - loss: 1.2199 - accuracy: 0.4781 - val_loss: 1.2847 - val_accuracy: 0.4559\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.1967 - accuracy: 0.4913 - val_loss: 1.2662 - val_accuracy: 0.4604\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 1.1735 - accuracy: 0.5028 - val_loss: 1.2669 - val_accuracy: 0.4621\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 1.1496 - accuracy: 0.5203 - val_loss: 1.2795 - val_accuracy: 0.4563\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 18s 357ms/step - loss: 1.1247 - accuracy: 0.5303 - val_loss: 1.3110 - val_accuracy: 0.4447\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 1.1003 - accuracy: 0.5439 - val_loss: 1.2467 - val_accuracy: 0.4763\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 1.0728 - accuracy: 0.5548 - val_loss: 1.2059 - val_accuracy: 0.4979\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 1.0396 - accuracy: 0.5724 - val_loss: 1.2199 - val_accuracy: 0.5024\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 1.0214 - accuracy: 0.5792 - val_loss: 1.2043 - val_accuracy: 0.5058\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 0.9874 - accuracy: 0.5914 - val_loss: 1.2298 - val_accuracy: 0.5202\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 18s 351ms/step - loss: 0.9595 - accuracy: 0.6070 - val_loss: 1.2092 - val_accuracy: 0.5249\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 18s 364ms/step - loss: 0.9323 - accuracy: 0.6173 - val_loss: 1.2592 - val_accuracy: 0.5187\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 18s 357ms/step - loss: 0.9017 - accuracy: 0.6326 - val_loss: 1.2046 - val_accuracy: 0.5296\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 18s 358ms/step - loss: 0.8684 - accuracy: 0.6470 - val_loss: 1.1993 - val_accuracy: 0.5387\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 0.8483 - accuracy: 0.6567 - val_loss: 1.2589 - val_accuracy: 0.5313\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 0.8213 - accuracy: 0.6661 - val_loss: 1.1750 - val_accuracy: 0.5475\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.7939 - accuracy: 0.6759 - val_loss: 1.2034 - val_accuracy: 0.5539\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.7670 - accuracy: 0.6871 - val_loss: 1.3167 - val_accuracy: 0.5481\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 0.7362 - accuracy: 0.7029 - val_loss: 1.2488 - val_accuracy: 0.5568\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.7026 - accuracy: 0.7167 - val_loss: 1.3171 - val_accuracy: 0.5616\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.6919 - accuracy: 0.7185 - val_loss: 1.2209 - val_accuracy: 0.5693\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 18s 369ms/step - loss: 0.6636 - accuracy: 0.7313 - val_loss: 1.2505 - val_accuracy: 0.5631\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 0.6392 - accuracy: 0.7425 - val_loss: 1.2676 - val_accuracy: 0.5623\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.6131 - accuracy: 0.7556 - val_loss: 1.2937 - val_accuracy: 0.5629\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 18s 363ms/step - loss: 0.5969 - accuracy: 0.7596 - val_loss: 1.2993 - val_accuracy: 0.5727\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 0.5787 - accuracy: 0.7711 - val_loss: 1.3096 - val_accuracy: 0.5606\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 0.5548 - accuracy: 0.7812 - val_loss: 1.3494 - val_accuracy: 0.5685\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.5320 - accuracy: 0.7903 - val_loss: 1.3453 - val_accuracy: 0.5764\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.5194 - accuracy: 0.7920 - val_loss: 1.3008 - val_accuracy: 0.5749\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.4984 - accuracy: 0.8027 - val_loss: 1.4825 - val_accuracy: 0.5712\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.4871 - accuracy: 0.8089 - val_loss: 1.4455 - val_accuracy: 0.5781\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.4637 - accuracy: 0.8178 - val_loss: 1.4274 - val_accuracy: 0.5811\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.4429 - accuracy: 0.8267 - val_loss: 1.5984 - val_accuracy: 0.5768\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.4232 - accuracy: 0.8336 - val_loss: 1.5813 - val_accuracy: 0.5769\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 17s 350ms/step - loss: 0.4223 - accuracy: 0.8348 - val_loss: 1.5684 - val_accuracy: 0.5813\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.3971 - accuracy: 0.8458 - val_loss: 1.6044 - val_accuracy: 0.5739\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 18s 358ms/step - loss: 0.3861 - accuracy: 0.8487 - val_loss: 1.5085 - val_accuracy: 0.5838\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 0.3719 - accuracy: 0.8534 - val_loss: 1.5124 - val_accuracy: 0.5832\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.3643 - accuracy: 0.8593 - val_loss: 1.6320 - val_accuracy: 0.5788\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    np.asarray(training_content_enc),\n",
    "    np.asarray(training_labels),\n",
    "    batch_size=batch_size,      # small batch size are better but costs a lot of time\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(\n",
    "        np.asarray(validating_content_enc),\n",
    "        np.asarray(validating_labels)),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model_label_encoding_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Deberta 🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import DebertaV2Tokenizer, TFDebertaV2Model\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFDebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier', 'pooler', 'cls_dropout']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_deberta = TFAutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", trainable=True, return_dict=True, num_labels=5, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying around Huggingfaces Model and Tokenizer Structure\n",
    "The following small try and errors for getting familiar with this framework is based on this huggingface documentation: https://huggingface.co/docs/transformers/glossary#:~:text=token%3A%20a%20part%20of%20a,based%20deep%20learning%20model%20architecture.\n",
    "\n",
    "And this might be interesting for the Tokenizer topic as well: https://huggingface.co/docs/transformers/preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with Deberta Tokenizer (🤗)\n",
    "Converting a test sentence with doberta tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_tok = tokenizer_bert('This is a Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 713, 16, 10, 4500, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the encoded results of the test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 713, 16, 10, 4500, 2]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_tok[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the encoded test sentence back to its original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]This is a Test[SEP]'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_bert.decode(test_text_tok[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"This is a test\"\n",
    "sentence_b = \"This is a test as well but its longer, much longer, longer than any other test could be\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding both sentences and retrieving the ids only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence a encoded: [1, 713, 16, 10, 1296, 2]\n",
      "sentence b encoded: [1, 713, 16, 10, 1296, 25, 157, 53, 63, 1181, 6, 203, 1181, 6, 1181, 87, 143, 97, 1296, 115, 28, 2]\n"
     ]
    }
   ],
   "source": [
    "encoded_sen_a = tokenizer_bert(sentence_a)[\"input_ids\"]\n",
    "encoded_sen_b = tokenizer_bert(sentence_b)[\"input_ids\"]\n",
    "\n",
    "print(f'sentence a encoded: {encoded_sen_a}')\n",
    "print(f'sentence b encoded: {encoded_sen_b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again tokenizing the sentences but with padding activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences encoded: [[1, 713, 16, 10, 1296, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 713, 16, 10, 1296, 25, 157, 53, 63, 1181, 6, 203, 1181, 6, 1181, 87, 143, 97, 1296, 115, 28, 2]]\n",
      "Sentences att.msk: [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "padded_sentences = tokenizer_bert([sentence_a, sentence_b], padding=True)\n",
    "\n",
    "print(f'Sentences encoded: {padded_sentences[\"input_ids\"]}')\n",
    "print(f'Sentences att.msk: {padded_sentences[\"attention_mask\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data for Deberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length is: 127\n"
     ]
    }
   ],
   "source": [
    "MAX_LINE_LENGTH_BERT = len(tokenizer_bert(X_train['corpus_w_full_context'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")[1])\n",
    "print(f\"Maximum sentence length is: {MAX_LINE_LENGTH_BERT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer_bert(examples['corpus_w_full_context'].tolist(), padding='max_length', truncation=True, return_tensors=\"tf\", max_length=MAX_LINE_LENGTH_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train-sentences [padded]: 127\n",
      "Length of the val-sentences [padded]: 127\n"
     ]
    }
   ],
   "source": [
    "#X_train.map(preprocess_function, batched=True)\n",
    "train_encoded = preprocess_function(X_train)\n",
    "val_encoded = preprocess_function(X_val)\n",
    "\n",
    "print(f'Length of the train-sentences [padded]: {train_encoded[\"input_ids\"].shape[1]}')\n",
    "print(f'Length of the val-sentences [padded]: {val_encoded[\"input_ids\"].shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels, that came from deberta model: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of labels, that came from deberta model: {model_deberta.num_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_ids_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n",
    "_attention_mask_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n",
    "\n",
    "x = model_deberta(\n",
    "                input_ids = _input_ids_,\n",
    "                attention_mask = _attention_mask_,\n",
    "                output_hidden_states=True\n",
    "                ),\n",
    "#print(x[0])\n",
    "#print('-----------------------------------')\n",
    "#print(x[0].hidden_states)\n",
    "#print('-----------------------------------')\n",
    "#print(x[0].hidden_states[-1])\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x[0].hidden_states[-1])\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs = [_input_ids_, _attention_mask_], \n",
    "                        outputs = output\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_deberta_for_sequence_classi  TFSequenceClassifie  139196165  ['input_11[0][0]',               \n",
      " fication_3 (TFDebertaForSequen  rOutput(loss=None,               'input_12[0][0]']               \n",
      " ceClassification)              logits=(None, 5),                                                 \n",
      "                                 hidden_states=((No                                               \n",
      "                                ne, 127, 768),                                                    \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768)),                                               \n",
      "                                 attentions=None)                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 768)         0           ['tf_deberta_for_sequence_classif\n",
      " obalAveragePooling1D)                                           ication_3[0][12]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 768)          0           ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 5)            3845        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 139,200,010\n",
      "Trainable params: 139,200,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_deberta_for_sequence_classification_3/pooler/dense/kernel:0', 'tf_deberta_for_sequence_classification_3/pooler/dense/bias:0', 'tf_deberta_for_sequence_classification_3/classifier/kernel:0', 'tf_deberta_for_sequence_classification_3/classifier/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_deberta_for_sequence_classification_3/pooler/dense/kernel:0', 'tf_deberta_for_sequence_classification_3/pooler/dense/bias:0', 'tf_deberta_for_sequence_classification_3/classifier/kernel:0', 'tf_deberta_for_sequence_classification_3/classifier/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "3192/3192 [==============================] - 1403s 427ms/step - loss: 1.1848 - accuracy: 0.4960 - val_loss: 0.9417 - val_accuracy: 0.6322 - lr: 1.0000e-05\n",
      "Epoch 2/3\n",
      "3192/3192 [==============================] - 1367s 428ms/step - loss: 0.9107 - accuracy: 0.6295 - val_loss: 0.9381 - val_accuracy: 0.6406 - lr: 5.0000e-06\n",
      "Epoch 3/3\n",
      "3192/3192 [==============================] - 1362s 427ms/step - loss: 0.8118 - accuracy: 0.6762 - val_loss: 0.8317 - val_accuracy: 0.6785 - lr: 3.3333e-06\n"
     ]
    }
   ],
   "source": [
    "history_deberta = model2.fit(x=(np.asarray(train_encoded['input_ids']),\n",
    "                                np.asarray(train_encoded['attention_mask'])\n",
    "                                ),\n",
    "                                y=np.asarray(training_labels),\n",
    "                                validation_data=((np.asarray(val_encoded['input_ids']),\n",
    "                                                  np.asarray(val_encoded['attention_mask'])),\n",
    "                                                np.asarray(validating_labels)\n",
    "                                                ),\n",
    "                                epochs=3,\n",
    "                                batch_size=8,\n",
    "                                callbacks =[tensorboard_callback_deberta, lr_callback]) #lr_callback rlrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"deberta_trained_3_epochs_decay_lr.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model2.load_weights('deberta_trained_4_runden.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(127,), dtype=int32, numpy=\n",
       "array([    1, 41328,  3940,  3858, 30438,  1862,    12, 47233, 32870,\n",
       "           2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encoded['input_ids'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 127) for input KerasTensor(type_spec=TensorSpec(shape=(None, 127), dtype=tf.int32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 127) for input KerasTensor(type_spec=TensorSpec(shape=(None, 127), dtype=tf.int32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_deberta_for_sequence_classification\" (type TFDebertaForSequenceClassification).\n    \n    in user code:\n    \n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 1249, in call  *\n            outputs = self.deberta(\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        StagingError: Exception encountered when calling layer \"deberta\" (type TFDebertaMainLayer).\n        \n        in user code:\n        \n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 948, in call  *\n                embedding_output = self.embeddings(\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            StagingError: Exception encountered when calling layer \"embeddings\" (type TFDebertaEmbeddings).\n            \n            in user code:\n            \n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 800, in call  *\n                    final_embeddings = self.LayerNorm(final_embeddings)\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\", line 270, in call\n                    broadcast_shape[dim] = input_shape.dims[dim].value\n            \n                IndexError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                list index out of range\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • inputs_embeds=None\n              • mask=tf.Tensor(shape=(None,), dtype=int32)\n              • training=False\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None,), dtype=int32)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n          • token_type_ids=None\n          • position_ids=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=True\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received:\n      • self=tf.Tensor(shape=(None,), dtype=int32)\n      • input_ids=None\n      • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n      • token_type_ids=None\n      • position_ids=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=True\n      • return_dict=None\n      • labels=None\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 86'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000085?line=0'>1</a>\u001b[0m model2\u001b[39m.\u001b[39;49mpredict((np\u001b[39m.\u001b[39;49masarray(val_encoded[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000085?line=1'>2</a>\u001b[0m                        np\u001b[39m.\u001b[39;49masarray(val_encoded[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m])),\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000085?line=2'>3</a>\u001b[0m                     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_deberta_for_sequence_classification\" (type TFDebertaForSequenceClassification).\n    \n    in user code:\n    \n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 1249, in call  *\n            outputs = self.deberta(\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        StagingError: Exception encountered when calling layer \"deberta\" (type TFDebertaMainLayer).\n        \n        in user code:\n        \n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 948, in call  *\n                embedding_output = self.embeddings(\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            StagingError: Exception encountered when calling layer \"embeddings\" (type TFDebertaEmbeddings).\n            \n            in user code:\n            \n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 800, in call  *\n                    final_embeddings = self.LayerNorm(final_embeddings)\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\", line 270, in call\n                    broadcast_shape[dim] = input_shape.dims[dim].value\n            \n                IndexError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                list index out of range\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • inputs_embeds=None\n              • mask=tf.Tensor(shape=(None,), dtype=int32)\n              • training=False\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None,), dtype=int32)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n          • token_type_ids=None\n          • position_ids=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=True\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received:\n      • self=tf.Tensor(shape=(None,), dtype=int32)\n      • input_ids=None\n      • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n      • token_type_ids=None\n      • position_ids=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=True\n      • return_dict=None\n      • labels=None\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "model2.predict((np.asarray(val_encoded['input_ids'][1]),\n",
    "                       np.asarray(val_encoded['attention_mask'][1])),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abatement act of abating FURNITURE  DOMESTIC ARTICLES OR APPLIANCES  COFFEE MILLS  SPICE MILLS  SUCTION CLEANERS IN GENERAL'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['corpus_w_full_context'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Value Test (Validation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded value of the validation label: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Decoded value of the validation label: {encoder.inverse_transform(validating_labels[2486])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 51) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 91'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000090?line=0'>1</a>\u001b[0m prediction_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model2\u001b[39m.\u001b[39;49mpredict(validating_content_enc[np\u001b[39m.\u001b[39;49mnewaxis , \u001b[39m2486\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000090?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModels prediciton for this single validation data is: \u001b[39m\u001b[39m{\u001b[39;00mencoder\u001b[39m.\u001b[39minverse_transform([prediction_value])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 51) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "prediction_value = np.argmax(model2.predict(validating_content_enc[np.newaxis , 2486]))\n",
    "print(f'Models prediciton for this single validation data is: {encoder.inverse_transform([prediction_value])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with all Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None)},),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 93'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000092?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mpredict(val_encoded)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py:426\u001b[0m, in \u001b[0;36mTypeSpec.__make_cmp_key\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    424\u001b[0m   \u001b[39mreturn\u001b[39;00m (np\u001b[39m.\u001b[39mndarray, value\u001b[39m.\u001b[39mshape,\n\u001b[0;32m    425\u001b[0m           TypeSpec\u001b[39m.\u001b[39m__nested_list_to_tuple(value\u001b[39m.\u001b[39mtolist()))\n\u001b[1;32m--> 426\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot generate a hashable key for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m because \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m                  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe _serialize() method \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m                  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturned an unsupproted value of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 127), dtype=tf.int32, name=None)},),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>"
     ]
    }
   ],
   "source": [
    "predictions = model2.predict(val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model2.evaluate((np.asarray(val_encoded['input_ids']),\n",
    "                              np.asarray(val_encoded['attention_mask']),\n",
    "                             ),\n",
    "                             validating_labels, verbose=0)\n",
    "\n",
    "print(f'Models validation loss: {evaluation[0]} - Models validation accuracy: {evaluation[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f790da36a0>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_deberta.history['loss'])\n",
    "plt.plot(history_deberta.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Test File Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_file = pd.DataFrame(columns=['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded = preprocess_function(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model2.predict((np.asarray(test_encoded['input_ids']),\n",
    "                                  np.asarray(test_encoded['attention_mask']) \n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_file['score'] = encoder.inverse_transform(np.argmax(test_prediction, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASKklEQVR4nO3df4xldXnH8fenu0INVVmknZBddGndpl1KijgBUts6agILTbtojYHasiDpthUaTWnStf6BAUn0D7XBKO1aNwsNFak/wqaspRvk1rTpIosiC1pkumLYFSG6IB1ttEue/nG/o9d1Zufunblzd3ber+Tmnvuc8z3n+8ww89l7zplLqgpJ0vL2M6OegCRp9AwDSZJhIEkyDCRJGAaSJGDlqCcwqFNPPbXWrl070Njvfe97nHTSSQs7oWOcPS8Py63n5dYvzL/nBx544NtV9fOH15dsGKxdu5Y9e/YMNLbT6TAxMbGwEzrG2fPysNx6Xm79wvx7TvKNmeqeJpIkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEkv4L5AlaZTWbrlrJMfdvmE4H7/hOwNJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJJEH2GQ5PQk9yb5SpJHkry91d+d5ECSB9vj4p4x70wymeTRJBf21De02mSSLT31M5Lc1+qfSHLCQjcqSZpdP+8MDgHXVtV64Hzg6iTr27oPVtXZ7bEToK27FDgT2AB8JMmKJCuADwMXAeuBy3r28762r1cAzwBXLVB/kqQ+zBkGVfVkVX2xLf8P8FVg9RGGbARur6ofVNXXgUng3PaYrKp9VfVD4HZgY5IArwM+2cbfAlwyYD+SpAEc1cdRJFkLvBK4D3g1cE2Sy4E9dN89PEM3KHb3DNvPj8PjicPq5wEvBZ6tqkMzbH/48TcDmwHGxsbodDpHM/0fmZqaGnjsUmXPy8Ny63mU/V571qG5NxqCYfXcdxgk+TngU8A7quq5JDcDNwDVnt8PvHXBZ9ijqrYCWwHGx8drYmJioP10Oh0GHbtU2fPysNx6HmW/V4zws4mG0XNfYZDkBXSD4Laq+jRAVT3Vs/6jwD+3lweA03uGr2k1Zql/Bzg5ycr27qB3e0nSIujnbqIAHwO+WlUf6Kmf1rPZG4CH2/IO4NIkJyY5A1gHfAG4H1jX7hw6ge5F5h1VVcC9wJva+E3AnfNrS5J0NPp5Z/Bq4I+AvUkebLW/pns30Nl0TxM9DvwJQFU9kuQO4Ct070S6uqqeB0hyDXA3sALYVlWPtP39FXB7kvcAX6IbPpKkRTJnGFTVvwOZYdXOI4y5EbhxhvrOmcZV1T66dxtJkkbAv0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJLoIwySnJ7k3iRfSfJIkre3+ilJdiV5rD2vavUkuSnJZJKHkpzTs69NbfvHkmzqqb8qyd425qYkGUazkqSZ9fPO4BBwbVWtB84Hrk6yHtgC3FNV64B72muAi4B17bEZuBm64QFcB5wHnAtcNx0gbZs/7hm3Yf6tSZL6NWcYVNWTVfXFtvw/wFeB1cBG4Ja22S3AJW15I3Brde0GTk5yGnAhsKuqDlbVM8AuYENb9+Kq2l1VBdzasy9J0iJYeTQbJ1kLvBK4Dxirqifbqm8BY215NfBEz7D9rXak+v4Z6jMdfzPddxuMjY3R6XSOZvo/MjU1NfDYpcqel4fl1vMo+732rEMjOe6weu47DJL8HPAp4B1V9Vzvaf2qqiS14LM7TFVtBbYCjI+P18TExED76XQ6DDp2qbLn5WG59TzKfq/YctdIjrt9w0lD6bmvu4mSvIBuENxWVZ9u5afaKR7a89OtfgA4vWf4mlY7Un3NDHVJ0iLp526iAB8DvlpVH+hZtQOYviNoE3BnT/3ydlfR+cB32+mku4ELkqxqF44vAO5u655Lcn471uU9+5IkLYJ+ThO9GvgjYG+SB1vtr4H3AnckuQr4BvDmtm4ncDEwCXwfuBKgqg4muQG4v213fVUdbMtvA7YDLwQ+2x6SpEUyZxhU1b8Ds933//oZti/g6ln2tQ3YNkN9D/Brc81FkjQc/gWyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEH2GQZFuSp5M83FN7d5IDSR5sj4t71r0zyWSSR5Nc2FPf0GqTSbb01M9Icl+rfyLJCQvZoCRpbv28M9gObJih/sGqOrs9dgIkWQ9cCpzZxnwkyYokK4APAxcB64HL2rYA72v7egXwDHDVfBqSJB29OcOgqj4PHOxzfxuB26vqB1X1dWASOLc9JqtqX1X9ELgd2JgkwOuAT7bxtwCXHF0LkqT5WjmPsdckuRzYA1xbVc8Aq4HdPdvsbzWAJw6rnwe8FHi2qg7NsP1PSbIZ2AwwNjZGp9MZaOJTU1MDj12q7Hl5WG49j7Lfa886NPdGQzCsngcNg5uBG4Bqz+8H3rpQk5pNVW0FtgKMj4/XxMTEQPvpdDoMOnapsuflYbn1PMp+r9hy10iOu33DSUPpeaAwqKqnppeTfBT45/byAHB6z6ZrWo1Z6t8BTk6ysr076N1ekrRIBrq1NMlpPS/fAEzfabQDuDTJiUnOANYBXwDuB9a1O4dOoHuReUdVFXAv8KY2fhNw5yBzkiQNbs53Bkk+DkwApybZD1wHTCQ5m+5poseBPwGoqkeS3AF8BTgEXF1Vz7f9XAPcDawAtlXVI+0QfwXcnuQ9wJeAjy1Uc5Kk/swZBlV12QzlWX9hV9WNwI0z1HcCO2eo76N7t5EkaUT8C2RJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIk+wiDJtiRPJ3m4p3ZKkl1JHmvPq1o9SW5KMpnkoSTn9IzZ1LZ/LMmmnvqrkuxtY25KkoVuUpJ0ZP28M9gObDistgW4p6rWAfe01wAXAevaYzNwM3TDA7gOOA84F7huOkDaNn/cM+7wY0mShmzOMKiqzwMHDytvBG5py7cAl/TUb62u3cDJSU4DLgR2VdXBqnoG2AVsaOteXFW7q6qAW3v2JUlaJINeMxirqifb8reAsba8GniiZ7v9rXak+v4Z6pKkRbRyvjuoqkpSCzGZuSTZTPf0E2NjY3Q6nYH28/TB7/Kh2+5cwJn156zVL1n0Y06bmpoa+Ou1VNnz8W+U/V571qGRHHdYPQ8aBk8lOa2qnmynep5u9QPA6T3brWm1A8DEYfVOq6+ZYfsZVdVWYCvA+Ph4TUxMzLbpEX3otjt5/9555+BRe/wtE4t+zGmdTodBv15LlT0f/0bZ7xVb7hrJcbdvOGkoPQ96mmgHMH1H0Cbgzp765e2uovOB77bTSXcDFyRZ1S4cXwDc3dY9l+T8dhfR5T37kiQtkjn/eZzk43T/VX9qkv107wp6L3BHkquAbwBvbpvvBC4GJoHvA1cCVNXBJDcA97ftrq+q6YvSb6N7x9ILgc+2hyRpEc0ZBlV12SyrXj/DtgVcPct+tgHbZqjvAX5trnlIkobHv0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJzDMMkjyeZG+SB5PsabVTkuxK8lh7XtXqSXJTkskkDyU5p2c/m9r2jyXZNL+WJElHayHeGby2qs6uqvH2egtwT1WtA+5prwEuAta1x2bgZuiGB3AdcB5wLnDddIBIkhbHME4TbQRuacu3AJf01G+trt3AyUlOAy4EdlXVwap6BtgFbBjCvCRJs1g5z/EF/GuSAv6uqrYCY1X1ZFv/LWCsLa8GnugZu7/VZqv/lCSb6b6rYGxsjE6nM9Ckx14I1551aKCx8zHofBfC1NTUSI8/CvZ8/Btlv6P4HQLD63m+YfCbVXUgyS8Au5L8V+/KqqoWFAuihc1WgPHx8ZqYmBhoPx+67U7ev3e+rR+9x98ysejHnNbpdBj067VU2fPxb5T9XrHlrpEcd/uGk4bS87xOE1XVgfb8NPAZuuf8n2qnf2jPT7fNDwCn9wxf02qz1SVJi2TgMEhyUpIXTS8DFwAPAzuA6TuCNgF3tuUdwOXtrqLzge+200l3AxckWdUuHF/QapKkRTKfcyVjwGeSTO/nH6vqX5LcD9yR5CrgG8Cb2/Y7gYuBSeD7wJUAVXUwyQ3A/W2766vq4DzmJUk6SgOHQVXtA359hvp3gNfPUC/g6ln2tQ3YNuhcJEnz418gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJHENhkGRDkkeTTCbZMur5SNJyckyEQZIVwIeBi4D1wGVJ1o92VpK0fBwTYQCcC0xW1b6q+iFwO7BxxHOSpGVj5agn0KwGnuh5vR847/CNkmwGNreXU0keHfB4pwLfHnDswPK+xT7iTxhJzyNmz8e/5dYvr33fvHt++UzFYyUM+lJVW4Gt891Pkj1VNb4AU1oy7Hl5WG49L7d+YXg9HyuniQ4Ap/e8XtNqkqRFcKyEwf3AuiRnJDkBuBTYMeI5SdKycUycJqqqQ0muAe4GVgDbquqRIR5y3qealiB7Xh6WW8/LrV8YUs+pqmHsV5K0hBwrp4kkSSNkGEiSjq8wmOsjLZJ8MMmD7fG1JM/2rHu+Z92SuXjdR88vS3Jvki8leSjJxT3r3tnGPZrkwsWd+eAG7TnJ2iT/2/N9/tvFn/1g+uj55Unuaf12kqzpWbcpyWPtsWlxZz64efa85H6ek2xL8nSSh2dZnyQ3ta/HQ0nO6Vk3/+9xVR0XD7oXnv8b+EXgBODLwPojbP/ndC9UT7+eGnUPw+iZ7sWmP2vL64HHe5a/DJwInNH2s2LUPQ2557XAw6PuYUg9/xOwqS2/DviHtnwKsK89r2rLq0bd0zB7bq+X4s/zbwPnzPbfKHAx8FkgwPnAfQv5PT6e3hkc7UdaXAZ8fFFmNjz99FzAi9vyS4BvtuWNwO1V9YOq+jow2fZ3rJtPz0tVPz2vBz7Xlu/tWX8hsKuqDlbVM8AuYMMizHm+5tPzklRVnwcOHmGTjcCt1bUbODnJaSzQ9/h4CoOZPtJi9UwbJnk53X8Nf66n/LNJ9iTZneSSoc1yYfXT87uBP0yyH9hJ9x1Rv2OPRfPpGeCMdvro35L81lBnunD66fnLwBvb8huAFyV5aZ9jj0Xz6RmW5s/zXGb7mizI9/h4CoOjcSnwyap6vqf28ur+ifcfAH+T5JdGM7UFdxmwvarW0H2b+Q9Jjvfv+2w9Pwm8rKpeCfwF8I9JXnyE/Swlfwm8JsmXgNfQ/Qv+5488ZMk7Us/H68/z0BxPvxSO5iMtLuWwU0RVdaA97wM6wCsXfooLrp+erwLuAKiq/wR+lu6Hey3VjwAZuOd2Suw7rf4A3XPSvzz0Gc/fnD1X1Ter6o0t6N7Vas/2M/YYNZ+el+rP81xm+5oszPd41BdNFvDiy0q6F07O4McXnM6cYbtfAR6n/cFdq60CTmzLpwKPcYSLz8fKo5+e6V5wuqIt/yrd8+cBzuQnLyDvY2lcQJ5Pzz8/3SPdC5MHgFNG3dMC9Xwq8DNt+Ubg+rZ8CvD19t/4qrZ8vPe8JH+e23zXMvsF5N/hJy8gf2Ehv8cjb36Bv5AXA1+j+y++d7Xa9cDv9WzzbuC9h437DWBv+w9uL3DVqHtZqJ7pXmT7j9bbg8AFPWPf1cY9Clw06l6G3TPw+8AjrfZF4HdH3csC9vym9kvva8DfT/8ybOveSvcGgUngylH3Muyel+rPM92zFU8C/0f3vP9VwJ8Cf9rWh+7/BOy/W1/jC/k99uMoJEnH1TUDSdKADANJkmEgSTIMJEkYBpIkDANJEoaBJAn4f0sC3paan4XCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "competition_file['score'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_file.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f886a0e7e4bdf7e8f253b33537ca1c5dcae8e086cc45ba5445b111bc8663c61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
