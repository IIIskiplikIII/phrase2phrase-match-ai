{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "---Tensorflow is running with GPU Power now---\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\sample_submission.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\test.csv\n",
      "f:\\python-workspace\\phrase2phrase-match-ai\\data\\input\\us-patent-phrase-to-phrase-matching\\train.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM, Bidirectional\n",
    "from keras.layers.merge import concatenate\n",
    "from transformers import BertTokenizer, TFDebertaModel\n",
    "\n",
    "#import mlflow\n",
    "#from mlflow import log_metric, log_param, log_artifacts\n",
    "#import mlflow.tensorflow\n",
    "#from mlflow import pyfunc\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "else:\n",
    "    print(f'---Tensorflow is running with GPU Power now---')\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "\n",
    "\n",
    "random_state=42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')\n",
    "#kaggle = 0 # Kaggle path active = 1\n",
    "\n",
    "MAIN_PATH = os.getcwd()\n",
    "\n",
    "# change your local path here\n",
    "if iskaggle:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'input')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH, 'us-patent-phrase-to-phrase-matching')\n",
    "else:\n",
    "    DATA_PATH = os.path.join(MAIN_PATH, 'data')\n",
    "    PHRASES_PATH = os.path.join(DATA_PATH,'input\\\\us-patent-phrase-to-phrase-matching')\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk(PHRASES_PATH): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\python-workspace\\\\phrase2phrase-match-ai\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of loaded trainset: 36473\n",
      "Length of loaded testset: 36\n",
      "Length of loaded cpc_codeset: 260476\n"
     ]
    }
   ],
   "source": [
    "# Data path and file\n",
    "CSV_FILE_TRAIN='train.csv'\n",
    "CSV_FILE_TEST='test.csv'\n",
    "CSV_FILE_CPC='titles.csv'\n",
    "CPC_PATH='input\\\\cpc-codes'\n",
    "\n",
    "def load_csv_data(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "def load_csv_data_manuel(path, csv_file):\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    csv_file = open(csv_path, 'r')\n",
    "    csv_data = csv_file.readlines()\n",
    "    csv_file.close()\n",
    "    return csv_data\n",
    "    \n",
    "\n",
    "train = load_csv_data(PHRASES_PATH,CSV_FILE_TRAIN)\n",
    "test = load_csv_data(PHRASES_PATH,CSV_FILE_TEST)\n",
    "cpc_code = load_csv_data(os.path.join(DATA_PATH, CPC_PATH), CSV_FILE_CPC)\n",
    "\n",
    "\n",
    "print(f'Length of loaded trainset: {len(train)}')\n",
    "print(f'Length of loaded testset: {len(test)}')\n",
    "print(f'Length of loaded cpc_codeset: {len(cpc_code)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(cpc_code.set_index('code'), on = 'context')\n",
    "test = test.join(cpc_code.set_index('code'), on = 'context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given Attributes\n",
    "- id - a unique identifier for a pair of phrases\n",
    "- anchor - the first phrase\n",
    "- target - the second phrase\n",
    "- context - the CPC classification (version 2021.05), which indicates the subject within which the similarity is to be scored\n",
    "- score - the similarity. This is sourced from a combination of one or more manual expert ratings.\n",
    "\n",
    "\n",
    "## Score\n",
    "The scores are in the 0-1 range with increments of 0.25 with the following meanings:\n",
    "\n",
    "- 1.0 - Very close match. This is typically an exact match except possibly for differences in conjugation, quantity (e.g. singular vs. plural), and addition or removal of stopwords (e.g. “the”, “and”, “or”).\n",
    "- 0.75 - Close synonym, e.g. “mobile phone” vs. “cellphone”. This also includes abbreviations, e.g. \"TCP\" -> \"transmission control protocol\".\n",
    "- 0.5 - Synonyms which don’t have the same meaning (same function, same properties). This includes broad-narrow (hyponym) and narrow-broad (hypernym) matches.\n",
    "- 0.25 - Somewhat related, e.g. the two phrases are in the same high level domain but are not synonyms. This also includes antonyms.\n",
    "- 0.0 - Unrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "component composite coating              152\n",
       "sheet supply roller                      150\n",
       "source voltage                           140\n",
       "perfluoroalkyl group                     136\n",
       "el display                               135\n",
       "                                        ... \n",
       "plug nozzle                                2\n",
       "shannon                                    2\n",
       "dry coating composition1                   2\n",
       "peripheral nervous system stimulation      1\n",
       "conduct conducting material                1\n",
       "Name: anchor, Length: 733, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['anchor'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anchor value has 733 different values. Lets look at the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "composition                    24\n",
       "data                           22\n",
       "metal                          22\n",
       "motor                          22\n",
       "assembly                       21\n",
       "                               ..\n",
       "switching switch over valve     1\n",
       "switching switch off valve      1\n",
       "switching over valve            1\n",
       "switching off valve             1\n",
       "wooden substrate                1\n",
       "Name: target, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target looks a little bit different. Here we have 29,340 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    12300\n",
       "0.25    11519\n",
       "0.00     7471\n",
       "0.75     4029\n",
       "1.00     1154\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['score'].value_counts(dropna=False).sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th>context</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abatement</th>\n",
       "      <th>A47</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A61</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">wiring trough</th>\n",
       "      <th>F16</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H02</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">wood article</th>\n",
       "      <th>B05</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B44</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  target  score  title  section  class  subclass  \\\n",
       "anchor        context                                                       \n",
       "abatement     A47      21      21     21     21       21     21         0   \n",
       "              A61       3       3      3      3        3      3         0   \n",
       "              A62       1       1      1      1        1      1         0   \n",
       "              C01       1       1      1      1        1      1         0   \n",
       "              F16       1       1      1      1        1      1         0   \n",
       "...                    ..     ...    ...    ...      ...    ...       ...   \n",
       "wiring trough F16      27      27     27     27       27     27         0   \n",
       "              H02      18      18     18     18       18     18         0   \n",
       "wood article  B05      28      28     28     28       28     28         0   \n",
       "              B27       1       1      1      1        1      1         0   \n",
       "              B44      27      27     27     27       27     27         0   \n",
       "\n",
       "                       group  main_group  \n",
       "anchor        context                     \n",
       "abatement     A47          0           0  \n",
       "              A61          0           0  \n",
       "              A62          0           0  \n",
       "              C01          0           0  \n",
       "              F16          0           0  \n",
       "...                      ...         ...  \n",
       "wiring trough F16          0           0  \n",
       "              H02          0           0  \n",
       "wood article  B05          0           0  \n",
       "              B27          0           0  \n",
       "              B44          0           0  \n",
       "\n",
       "[1699 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['anchor', 'context']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing cpc text \n",
    "# Build a function around it ?????? !!!!!!!!!!!!!!!!!\n",
    "train['title'] = train.title.apply(lambda text: text.split(';'))\n",
    "train['title'] = train.title.apply(lambda context: ' '.join(context))\n",
    "\n",
    "#train.title.apply(lambda text: (lambda text: text.split(';'))(' '.join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corpus'] = train['anchor'] + ' ' + train['target']\n",
    "train['corpus_w_context'] = train['corpus'] + ' ' +  train['context']\n",
    "train['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']\n",
    "\n",
    "test['corpus'] = test['anchor'] + ' ' + test['target']\n",
    "#test['corpus_w_full_context'] = train['corpus'] + ' ' + train['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifing the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['id','score']].copy()\n",
    "X = train[['id','anchor','target','context', 'corpus', 'title', 'corpus_w_context', 'corpus_w_full_context']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training_target - list: 25531\n",
      "Length of training_content - list: 25531\n",
      "Length of training_content_w_context - list: 25531\n",
      "Length of training_content_full - list: 25531\n",
      "Length of validating_content - list: 10942\n",
      "Length of validating_content_w_context - list: 10942\n",
      "Length of validating_content_full - list: 10942\n",
      "Length of test_content - list: 36\n"
     ]
    }
   ],
   "source": [
    "training_target = X_train['target']\n",
    "print(f'Length of training_target - list: {len(training_target)}')\n",
    "\n",
    "training_content = X_train['corpus']\n",
    "print(f'Length of training_content - list: {len(training_content)}')\n",
    "\n",
    "training_content_w_context = X_train['corpus_w_context']\n",
    "print(f'Length of training_content_w_context - list: {len(training_content_w_context)}')\n",
    "\n",
    "training_content_full = X_train['corpus_w_full_context']\n",
    "print(f'Length of training_content_full - list: {len(training_content_full)}')\n",
    "\n",
    "\n",
    "validating_content = X_val['corpus']\n",
    "print(f'Length of validating_content - list: {len(validating_content)}')\n",
    "\n",
    "validating_content_w_context = X_val['corpus_w_context']\n",
    "print(f'Length of validating_content_w_context - list: {len(validating_content_w_context)}')\n",
    "\n",
    "validating_content_full = X_val['corpus_w_full_context']\n",
    "print(f'Length of validating_content_full - list: {len(validating_content_full)}')\n",
    "\n",
    "\n",
    "test_content = test['corpus']\n",
    "print(f'Length of test_content - list: {len(test_content)}')\n",
    "\n",
    "\n",
    "training_labels = y_train['score']\n",
    "validating_labels = y_val['score']\n",
    "\n",
    "training_labels = np.asarray(training_labels)\n",
    "validating_labels = np.asarray(validating_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train['score'])\n",
    "\n",
    "training_labels = encoder.transform(training_labels)\n",
    "validating_labels = encoder.transform(validating_labels)\n",
    "\n",
    "training_labels = training_labels.reshape(-1, 1)\n",
    "validating_labels = validating_labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Encoding and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(document, alpha=True):\n",
    "    '''Extracing words from a sentence or full text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document: str\n",
    "        Text that needs to be tokenized by nltk word_tokenize.\n",
    "    alpha: bool\n",
    "        Keep only letters or not. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of words from the given text.\n",
    "    '''\n",
    "    if alpha == True:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "            if any(c.isalpha() for c in word)\n",
    "        )\n",
    "    else:\n",
    "        return set(\n",
    "            word.lower() for word in nltk.word_tokenize(document)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(docs):\n",
    "    content = []\n",
    "    for doc in docs:\n",
    "        content.append(extract_words(doc))\n",
    "    return content\n",
    "\n",
    "def max_length(lines):\n",
    "    return max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(sequences, maxlen=length)\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(training_content_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_line_length = max_length(training_content_full)\n",
    "word_count = tokenizer.word_counts\n",
    "word_index = tokenizer.word_index\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training set (encoded): (25531, 51)\n",
      "Shape validating set (encoded): (10942, 51)\n",
      "Vocabulary size: 7750\n",
      "Max line lenght: 51\n"
     ]
    }
   ],
   "source": [
    "training_content_enc = encode_text(tokenizer, training_content_full, max_line_length)\n",
    "print(f'Shape training set (encoded): {training_content_enc.shape}')\n",
    "\n",
    "validating_content_enc = encode_text(tokenizer, validating_content_full, max_line_length)\n",
    "print(f'Shape validating set (encoded): {validating_content_enc.shape}')\n",
    "\n",
    "print(f'Vocabulary size: {vocab_size}')\n",
    "print(f'Max line lenght: {max_line_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development Based on Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = os.path.join(\n",
    "    os.getcwd(), \"data\\\\glove.6B\\\\glove.6B.300d.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(path_to_glove_file ,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params for the Glove based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main params for the model\n",
    "embedding_dim = 300 # according to the pretrained network\n",
    "hits = 0\n",
    "misses = 0\n",
    "lr = 0.00001\n",
    "batch_size = 512\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a corresponding embedding matrix for the Embedding layer in Keras.\n",
    "\n",
    "According to the choosen pre-trained embedding matrix we need to set the embedding dimension on 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7245 words (504 misses)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words ({misses} misses)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new Embedding Layer\n",
    "Now loading the pre-trained word embedding matrix into the embedding layer. According to the pre-trained embedding load the trainable param needst to be set on \"False\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    keras.layers.Embedding(    \n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        input_shape = [None],\n",
    "        input_length=max_line_length,\n",
    "        mask_zero=True,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable = False),\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    #keras.layers.LayerNormalization(),\n",
    "    #Bidirectional(keras.layers.LSTM(300, return_sequences=True)),\n",
    "    #keras.layers.LSTM(300),\n",
    "    #keras.layers.MultiHeadAttention(key_dim=254, num_heads=4, value_dim=20, dropout=0.25),\n",
    "    keras.layers.LSTM(300, return_sequences=True),\n",
    "    keras.layers.LSTM(300),\n",
    "    #keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dropout(0.5), \n",
    "    #keras.layers.Dense(128),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax' )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #optimizer=keras.optimizers.Nadam(learning_rate=lr, beta_1=mmt),\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 300)         2325000   \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, None, 300)        0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, None, 300)         721200    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dropout_376 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 5)                 1505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,770,105\n",
      "Trainable params: 1,444,505\n",
      "Non-trainable params: 2,325,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000047?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mplot_model(model, show_shapes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultichannel.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, to_file='multichannel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logging structure function\n",
    "root_logdir = \"../../tensorboard-logs\"\n",
    "\n",
    "def get_run_logdir(root_logdir, project):\n",
    "    '''\n",
    "    Returns logdir to the Tensorboard log for a specific project.\n",
    "\n",
    "            Parameters:\n",
    "                    root_logdir (str) : basic logdir from Tensorboard\n",
    "                    project (str): projectname that will be logged in TB\n",
    "\n",
    "            Returns:\n",
    "                    os.path (str): Path to the final logdir\n",
    "    '''\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    project_logdir = os.path.join(root_logdir,project)\n",
    "    return os.path.join(project_logdir, run_id)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  learning_rate = lr\n",
    "  if epoch > 10:\n",
    "    learning_rate = 0.002\n",
    "  if epoch > 20:\n",
    "    learning_rate = 0.0005\n",
    "  if epoch > 30:\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase\"), histogram_freq=1)\n",
    "tensorboard_callback_deberta = tf.keras.callbacks.TensorBoard(log_dir=get_run_logdir(root_logdir,\"nlp_phrase2phrase_deberta\"), histogram_freq=1)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cb152ca310>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([lr_schedule(e) for e in range(num_epochs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 26s 401ms/step - loss: 1.6401 - accuracy: 0.3201 - val_loss: 1.5247 - val_accuracy: 0.3522\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 1.4410 - accuracy: 0.3567 - val_loss: 1.4983 - val_accuracy: 0.3599\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.3816 - accuracy: 0.3817 - val_loss: 1.4925 - val_accuracy: 0.3388\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 1.3577 - accuracy: 0.3944 - val_loss: 1.4865 - val_accuracy: 0.3625\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 18s 363ms/step - loss: 1.3438 - accuracy: 0.4066 - val_loss: 1.4833 - val_accuracy: 0.3463\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 1.3295 - accuracy: 0.4169 - val_loss: 1.4579 - val_accuracy: 0.3743\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 1.3149 - accuracy: 0.4283 - val_loss: 1.4484 - val_accuracy: 0.3923\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.2963 - accuracy: 0.4389 - val_loss: 1.3998 - val_accuracy: 0.3992\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 18s 361ms/step - loss: 1.2794 - accuracy: 0.4484 - val_loss: 1.3562 - val_accuracy: 0.4113\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 1.2608 - accuracy: 0.4590 - val_loss: 1.3548 - val_accuracy: 0.4128\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 1.2453 - accuracy: 0.4665 - val_loss: 1.3104 - val_accuracy: 0.4174\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 18s 371ms/step - loss: 1.2199 - accuracy: 0.4781 - val_loss: 1.2847 - val_accuracy: 0.4559\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 1.1967 - accuracy: 0.4913 - val_loss: 1.2662 - val_accuracy: 0.4604\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 1.1735 - accuracy: 0.5028 - val_loss: 1.2669 - val_accuracy: 0.4621\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 1.1496 - accuracy: 0.5203 - val_loss: 1.2795 - val_accuracy: 0.4563\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 18s 357ms/step - loss: 1.1247 - accuracy: 0.5303 - val_loss: 1.3110 - val_accuracy: 0.4447\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 1.1003 - accuracy: 0.5439 - val_loss: 1.2467 - val_accuracy: 0.4763\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 1.0728 - accuracy: 0.5548 - val_loss: 1.2059 - val_accuracy: 0.4979\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 1.0396 - accuracy: 0.5724 - val_loss: 1.2199 - val_accuracy: 0.5024\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 1.0214 - accuracy: 0.5792 - val_loss: 1.2043 - val_accuracy: 0.5058\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 0.9874 - accuracy: 0.5914 - val_loss: 1.2298 - val_accuracy: 0.5202\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 18s 351ms/step - loss: 0.9595 - accuracy: 0.6070 - val_loss: 1.2092 - val_accuracy: 0.5249\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 18s 364ms/step - loss: 0.9323 - accuracy: 0.6173 - val_loss: 1.2592 - val_accuracy: 0.5187\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 18s 357ms/step - loss: 0.9017 - accuracy: 0.6326 - val_loss: 1.2046 - val_accuracy: 0.5296\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 18s 358ms/step - loss: 0.8684 - accuracy: 0.6470 - val_loss: 1.1993 - val_accuracy: 0.5387\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 0.8483 - accuracy: 0.6567 - val_loss: 1.2589 - val_accuracy: 0.5313\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 0.8213 - accuracy: 0.6661 - val_loss: 1.1750 - val_accuracy: 0.5475\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.7939 - accuracy: 0.6759 - val_loss: 1.2034 - val_accuracy: 0.5539\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.7670 - accuracy: 0.6871 - val_loss: 1.3167 - val_accuracy: 0.5481\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 0.7362 - accuracy: 0.7029 - val_loss: 1.2488 - val_accuracy: 0.5568\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.7026 - accuracy: 0.7167 - val_loss: 1.3171 - val_accuracy: 0.5616\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.6919 - accuracy: 0.7185 - val_loss: 1.2209 - val_accuracy: 0.5693\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 18s 369ms/step - loss: 0.6636 - accuracy: 0.7313 - val_loss: 1.2505 - val_accuracy: 0.5631\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 0.6392 - accuracy: 0.7425 - val_loss: 1.2676 - val_accuracy: 0.5623\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.6131 - accuracy: 0.7556 - val_loss: 1.2937 - val_accuracy: 0.5629\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 18s 363ms/step - loss: 0.5969 - accuracy: 0.7596 - val_loss: 1.2993 - val_accuracy: 0.5727\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 0.5787 - accuracy: 0.7711 - val_loss: 1.3096 - val_accuracy: 0.5606\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 0.5548 - accuracy: 0.7812 - val_loss: 1.3494 - val_accuracy: 0.5685\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.5320 - accuracy: 0.7903 - val_loss: 1.3453 - val_accuracy: 0.5764\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.5194 - accuracy: 0.7920 - val_loss: 1.3008 - val_accuracy: 0.5749\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 0.4984 - accuracy: 0.8027 - val_loss: 1.4825 - val_accuracy: 0.5712\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.4871 - accuracy: 0.8089 - val_loss: 1.4455 - val_accuracy: 0.5781\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.4637 - accuracy: 0.8178 - val_loss: 1.4274 - val_accuracy: 0.5811\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.4429 - accuracy: 0.8267 - val_loss: 1.5984 - val_accuracy: 0.5768\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.4232 - accuracy: 0.8336 - val_loss: 1.5813 - val_accuracy: 0.5769\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 17s 350ms/step - loss: 0.4223 - accuracy: 0.8348 - val_loss: 1.5684 - val_accuracy: 0.5813\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.3971 - accuracy: 0.8458 - val_loss: 1.6044 - val_accuracy: 0.5739\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 18s 358ms/step - loss: 0.3861 - accuracy: 0.8487 - val_loss: 1.5085 - val_accuracy: 0.5838\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 18s 356ms/step - loss: 0.3719 - accuracy: 0.8534 - val_loss: 1.5124 - val_accuracy: 0.5832\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.3643 - accuracy: 0.8593 - val_loss: 1.6320 - val_accuracy: 0.5788\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    np.asarray(training_content_enc),\n",
    "    np.asarray(training_labels),\n",
    "    batch_size=batch_size,      # small batch size are better but costs a lot of time\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(\n",
    "        np.asarray(validating_content_enc),\n",
    "        np.asarray(validating_labels)),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model_label_encoding_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on Deberta 🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import DebertaV2Tokenizer, TFDebertaV2Model\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFDebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier', 'cls_dropout', 'pooler']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_deberta = TFAutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", trainable=True, return_dict=True, num_labels=5, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying around Huggingfaces Model and Tokenizer Structure\n",
    "The following small try and errors for getting familiar with this framework is based on this huggingface documentation: https://huggingface.co/docs/transformers/glossary#:~:text=token%3A%20a%20part%20of%20a,based%20deep%20learning%20model%20architecture.\n",
    "\n",
    "And this might be interesting for the Tokenizer topic as well: https://huggingface.co/docs/transformers/preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with Deberta Tokenizer (🤗)\n",
    "Converting a test sentence with doberta tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_tok = tokenizer_bert('This is a Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 713, 16, 10, 4500, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the encoded results of the test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 713, 16, 10, 4500, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_tok[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the encoded test sentence back to its original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]This is a Test[SEP]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_bert.decode(test_text_tok[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"This is a test\"\n",
    "sentence_b = \"This is a test as well but its longer, much longer, longer than any other test could be\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding both sentences and retrieving the ids only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence a encoded: [1, 713, 16, 10, 1296, 2]\n",
      "sentence b encoded: [1, 713, 16, 10, 1296, 25, 157, 53, 63, 1181, 6, 203, 1181, 6, 1181, 87, 143, 97, 1296, 115, 28, 2]\n"
     ]
    }
   ],
   "source": [
    "encoded_sen_a = tokenizer_bert(sentence_a)[\"input_ids\"]\n",
    "encoded_sen_b = tokenizer_bert(sentence_b)[\"input_ids\"]\n",
    "\n",
    "print(f'sentence a encoded: {encoded_sen_a}')\n",
    "print(f'sentence b encoded: {encoded_sen_b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again tokenizing the sentences but with padding activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences encoded: [[1, 713, 16, 10, 1296, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 713, 16, 10, 1296, 25, 157, 53, 63, 1181, 6, 203, 1181, 6, 1181, 87, 143, 97, 1296, 115, 28, 2]]\n",
      "Sentences att.msk: [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "padded_sentences = tokenizer_bert([sentence_a, sentence_b], padding=True)\n",
    "\n",
    "print(f'Sentences encoded: {padded_sentences[\"input_ids\"]}')\n",
    "print(f'Sentences att.msk: {padded_sentences[\"attention_mask\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data for Deberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length is: 127\n"
     ]
    }
   ],
   "source": [
    "MAX_LINE_LENGTH_BERT = len(tokenizer_bert(X_train['corpus_w_full_context'].tolist(), padding=True, truncation=True, return_tensors=\"tf\")[1])\n",
    "print(f\"Maximum sentence length is: {MAX_LINE_LENGTH_BERT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer_bert(examples['corpus_w_full_context'].tolist(), padding='max_length', truncation=True, return_tensors=\"tf\", max_length=MAX_LINE_LENGTH_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train-sentences [padded]: 127\n",
      "Length of the val-sentences [padded]: 127\n"
     ]
    }
   ],
   "source": [
    "#X_train.map(preprocess_function, batched=True)\n",
    "train_encoded = preprocess_function(X_train)\n",
    "val_encoded = preprocess_function(X_val)\n",
    "\n",
    "print(f'Length of the train-sentences [padded]: {train_encoded[\"input_ids\"].shape[1]}')\n",
    "print(f'Length of the val-sentences [padded]: {val_encoded[\"input_ids\"].shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels, that came from deberta model: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of labels, that came from deberta model: {model_deberta.num_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFSequenceClassifierOutput(loss=None, logits=<KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, hidden_states=(<KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>), attentions=None)\n",
      "-----------------------------------\n",
      "(<KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>, <KerasTensor: shape=(None, 127, 768) dtype=float32 (created by layer 'tf_deberta_for_sequence_classification_1')>)\n",
      "-----------------------------------\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 127, 768), dtype=tf.float32, name=None), name='tf_deberta_for_sequence_classification_1/deberta/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_deberta_for_sequence_classification_1'\")\n"
     ]
    }
   ],
   "source": [
    "_input_ids_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n",
    "_attention_mask_ = tf.keras.Input(shape = (MAX_LINE_LENGTH_BERT, ), dtype = tf.int32)\n",
    "\n",
    "x = model_deberta(\n",
    "                input_ids = _input_ids_,\n",
    "                attention_mask = _attention_mask_,\n",
    "                output_hidden_states=True\n",
    "                ),\n",
    "print(x[0])\n",
    "print('-----------------------------------')\n",
    "print(x[0].hidden_states)\n",
    "print('-----------------------------------')\n",
    "print(x[0].hidden_states[-1])\n",
    "#x = tf.keras.layers.Dense(32)(x[0].logits)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x[0].hidden_states[-1])\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(5)(x)\n",
    "\n",
    "\n",
    "model2 = tf.keras.Model(inputs = [_input_ids_, _attention_mask_], \n",
    "                        outputs = output\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 127)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_deberta_for_sequence_classi  TFSequenceClassifie  139196165  ['input_27[0][0]',               \n",
      " fication_1 (TFDebertaForSequen  rOutput(loss=None,               'input_28[0][0]']               \n",
      " ceClassification)              logits=(None, 5),                                                 \n",
      "                                 hidden_states=((No                                               \n",
      "                                ne, 127, 768),                                                    \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768),                                                \n",
      "                                 (None, 127, 768)),                                               \n",
      "                                 attentions=None)                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 768)         0           ['tf_deberta_for_sequence_classif\n",
      " lobalAveragePooling1D)                                          ication_1[13][12]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 768)         3072        ['global_average_pooling1d_10[0][\n",
      " alization)                                                      0]']                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5)            3845        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 139,203,082\n",
      "Trainable params: 139,201,546\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3192/3192 [==============================] - 1214s 380ms/step - loss: 1.9067 - val_loss: 1.6256\n",
      "Epoch 2/5\n",
      "3192/3192 [==============================] - 1213s 380ms/step - loss: 1.6230 - val_loss: 1.6095\n",
      "Epoch 3/5\n",
      "3192/3192 [==============================] - 1211s 379ms/step - loss: 1.6094 - val_loss: 1.6095\n",
      "Epoch 4/5\n",
      "3192/3192 [==============================] - 1210s 379ms/step - loss: 1.6094 - val_loss: 1.6095\n",
      "Epoch 5/5\n",
      "3192/3192 [==============================] - 1202s 377ms/step - loss: 1.6094 - val_loss: 1.6095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbe04e9f10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_deberta = model2.fit(x=(np.asarray(train_encoded['input_ids']),\n",
    "                                np.asarray(train_encoded['attention_mask'])\n",
    "                                ),\n",
    "                                y=np.asarray(training_labels),\n",
    "                                validation_data=((np.asarray(val_encoded['input_ids']),\n",
    "                                                  np.asarray(val_encoded['attention_mask'])),\n",
    "                                                np.asarray(validating_labels)\n",
    "                                                ),\n",
    "                                epochs=5,\n",
    "                                batch_size=8,\n",
    "                                callbacks =[tensorboard_callback_deberta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"deberta_trained_11.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 127) for input KerasTensor(type_spec=TensorSpec(shape=(None, 127), dtype=tf.int32, name='input_27'), name='input_27', description=\"created by layer 'input_27'\"), but it was called on an input with incompatible shape (None,).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 127) for input KerasTensor(type_spec=TensorSpec(shape=(None, 127), dtype=tf.int32, name='input_28'), name='input_28', description=\"created by layer 'input_28'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_deberta_for_sequence_classification_1\" (type TFDebertaForSequenceClassification).\n    \n    in user code:\n    \n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 1249, in call  *\n            outputs = self.deberta(\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        StagingError: Exception encountered when calling layer \"deberta\" (type TFDebertaMainLayer).\n        \n        in user code:\n        \n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 948, in call  *\n                embedding_output = self.embeddings(\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            StagingError: Exception encountered when calling layer \"embeddings\" (type TFDebertaEmbeddings).\n            \n            in user code:\n            \n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 800, in call  *\n                    final_embeddings = self.LayerNorm(final_embeddings)\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\", line 270, in call\n                    broadcast_shape[dim] = input_shape.dims[dim].value\n            \n                IndexError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                list index out of range\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • inputs_embeds=None\n              • mask=tf.Tensor(shape=(None,), dtype=int32)\n              • training=False\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None,), dtype=int32)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n          • token_type_ids=None\n          • position_ids=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=True\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received:\n      • self=tf.Tensor(shape=(None,), dtype=int32)\n      • input_ids=None\n      • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n      • token_type_ids=None\n      • position_ids=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=True\n      • return_dict=None\n      • labels=None\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 84'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000084?line=0'>1</a>\u001b[0m model2\u001b[39m.\u001b[39;49mpredict((np\u001b[39m.\u001b[39;49masarray(val_encoded[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000084?line=1'>2</a>\u001b[0m                        np\u001b[39m.\u001b[39;49masarray(val_encoded[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m])),\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000084?line=2'>3</a>\u001b[0m                     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    StagingError: Exception encountered when calling layer \"tf_deberta_for_sequence_classification_1\" (type TFDebertaForSequenceClassification).\n    \n    in user code:\n    \n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 1249, in call  *\n            outputs = self.deberta(\n        File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        StagingError: Exception encountered when calling layer \"deberta\" (type TFDebertaMainLayer).\n        \n        in user code:\n        \n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1236, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 948, in call  *\n                embedding_output = self.embeddings(\n            File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            StagingError: Exception encountered when calling layer \"embeddings\" (type TFDebertaEmbeddings).\n            \n            in user code:\n            \n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\transformers\\models\\deberta\\modeling_tf_deberta.py\", line 800, in call  *\n                    final_embeddings = self.LayerNorm(final_embeddings)\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\layers\\normalization\\layer_normalization.py\", line 270, in call\n                    broadcast_shape[dim] = input_shape.dims[dim].value\n            \n                IndexError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                list index out of range\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • position_ids=None\n              • token_type_ids=tf.Tensor(shape=(None,), dtype=int32)\n              • inputs_embeds=None\n              • mask=tf.Tensor(shape=(None,), dtype=int32)\n              • training=False\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None,), dtype=int32)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n          • token_type_ids=None\n          • position_ids=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=True\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received:\n      • self=tf.Tensor(shape=(None,), dtype=int32)\n      • input_ids=None\n      • attention_mask=tf.Tensor(shape=(None,), dtype=int32)\n      • token_type_ids=None\n      • position_ids=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=True\n      • return_dict=None\n      • labels=None\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "model2.predict((np.asarray(val_encoded['input_ids'][1]),\n",
    "                       np.asarray(val_encoded['attention_mask'][1])),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abatement act of abating FURNITURE  DOMESTIC ARTICLES OR APPLIANCES  COFFEE MILLS  SPICE MILLS  SUCTION CLEANERS IN GENERAL'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['corpus_w_full_context'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Value Test (Validation Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label for this validation set: [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoded label for this validation set: {validating_labels[2486]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded value of the validation label: [0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Decoded value of the validation label: {encoder.inverse_transform(validating_labels[2486])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 51) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\python-workspace\\phrase2phrase-match-ai\\phrase_2_phrase_matching.ipynb Cell 90'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000096?line=0'>1</a>\u001b[0m prediction_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model2\u001b[39m.\u001b[39;49mpredict(validating_content_enc[np\u001b[39m.\u001b[39;49mnewaxis , \u001b[39m2486\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python-workspace/phrase2phrase-match-ai/phrase_2_phrase_matching.ipynb#ch0000096?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModels prediciton for this single validation data is: \u001b[39m\u001b[39m{\u001b[39;00mencoder\u001b[39m.\u001b[39minverse_transform([prediction_value])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\anaconda3\\envs\\wingpuflake_keras_GPU\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 51) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "prediction_value = np.argmax(model2.predict(validating_content_enc[np.newaxis , 2486]))\n",
    "print(f'Models prediciton for this single validation data is: {encoder.inverse_transform([prediction_value])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with all Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(validating_content_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy is - 0.3624565899372101\n"
     ]
    }
   ],
   "source": [
    "evaluation = model2.evaluate(validating_content_enc, validating_labels, verbose=0)\n",
    "print(f'Models accuracy is - {evaluation[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f575d6a190>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_deberta.history['loss'])\n",
    "plt.plot(history_deberta.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Test File Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_competition_file = pd.DataFrame(columns=['id','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test data.\n",
    "test_content_enc = encode_text(tokenizer, test_content, max_line_length)\n",
    "print(f'Shape training set (encoded): {test_content_enc.shape}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f886a0e7e4bdf7e8f253b33537ca1c5dcae8e086cc45ba5445b111bc8663c61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
